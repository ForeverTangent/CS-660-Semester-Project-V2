{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-660 Semester Project Notebook 1\n",
    "\n",
    "## Stan Rosenbaum\n",
    "\n",
    "Fall 2017\n",
    "\n",
    "Anaconda 5 / Python 3\n",
    "\n",
    "Using Keras with TensorFlow as back end.\n",
    "\n",
    "### Background Important Stuff\n",
    "\n",
    "First the Enums of the Classes\n",
    "\n",
    "* \"NA\" = 0\n",
    "* \"UP\" = 1\n",
    "* \"DOWN\" = 2\n",
    "* \"HOLE\" = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS660DataManagementCheck Imported\n"
     ]
    }
   ],
   "source": [
    "# First we init stuff.\n",
    "# Load the Basic Python Libraries\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "# Load my Data Management Module\n",
    "import CS660DataManagement as csDM\n",
    "import HumanOracle as hO\n",
    "\n",
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Load Keras Stuff\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "# Other.  Mostly Graphic stuff for displaying Data in and out of Jupyter.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Not using Quiver Yet.\n",
    "# from quiver_engine import server\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Processed Data Directory.\n",
    "processedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PROCESSED' )\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "pickleDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PICKLES' )\n",
    "modelsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS' )\n",
    "modelsStructsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS_STRUCTS' )\n",
    "weightsDirectory = os.path.join( os.getcwd(), os.pardir, 'WEIGHTS' )\n",
    "resultsDirectory = os.path.join( os.getcwd(), os.pardir, 'RESULTS' )\n",
    "\n",
    "testImageColorFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'ICOLOR', 'TEST.png' )\n",
    "testImageDepthFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'IDEPTH', 'TEST.png' )\n",
    "testCSVFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'PCLOUD', 'TEST.csv' )\n",
    "\n",
    "tensorLogDataDir = os.path.join( os.getcwd(), os.pardir, 'TENSOR_LOGS' )\n",
    "\n",
    "imageDirs = ['ICOLOR', 'IDEPTH']\n",
    "csvDirs = ['PCLOUD']\n",
    "\n",
    "allDataFlavors = imageDirs + csvDirs\n",
    "\n",
    "#Load main data file.\n",
    "searCSVInfoFile = os.path.join( combinedDataDir, 'SEAR_DC_INFO.csv' )\n",
    "\n",
    "csDM.CS660DataManagementCheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Data\n",
    "\n",
    "Unless we need to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Loaded.\n"
     ]
    }
   ],
   "source": [
    "def loadModel( modelName ):\n",
    "    \"\"\"\n",
    "    Loads the Model.\n",
    "    \"\"\"\n",
    "    theModel = load_model( os.path.join( modelsDirectory, modelName) )\n",
    "    print('MODEL Loaded.')\n",
    "    return theModel\n",
    "\n",
    "\n",
    "theModel = loadModel( 'JUPYTER_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Everything Saved\n"
     ]
    }
   ],
   "source": [
    "def saveModelEverything( theModel, modelName ):\n",
    "    \"\"\"\n",
    "    Saved Everything in regards to the model.\n",
    "    \"\"\"\n",
    "    saveModelStructure( theModel, modelName )\n",
    "    saveModel( theModel, modelName )\n",
    "    saveModelJSON( theModel, modelName )\n",
    "    saveModelWeights( theModel, modelName )\n",
    "    \n",
    "    print(\"Model Everything Saved\")\n",
    "    \n",
    "\n",
    "def saveModelStructure( theModel, modelStructureName ):\n",
    "    \"\"\"\n",
    "    Saves an image of the Model Structure.\n",
    "    \"\"\"\n",
    "    modelStructsFilePath = os.path.join(modelsStructsDirectory, modelStructureName )\n",
    "    plot_model(theModel, to_file=modelStructsFilePath)\n",
    "\n",
    "\n",
    "def saveModelJSON( model, modelName ):\n",
    "    \"\"\"\n",
    "    Saves the Model as JSON\n",
    "    Args:\n",
    "        model: the Keras NN Model\n",
    "        modelName: the Name\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    modelFilePath = os.path.join( modelsDirectory, modelName + '.json' )\n",
    "    model_json = theModel.to_json()\n",
    "    with open( modelFilePath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "        \n",
    "def saveModel( model, modelName ):\n",
    "    \"\"\"\n",
    "    Save the model, in Keras [h5] format.\n",
    "    \"\"\"\n",
    "    theModel.save(os.path.join( modelsDirectory, modelName ))\n",
    "\n",
    "    \n",
    "def saveModelWeights( theModel, modelName ):\n",
    "    \"\"\"\n",
    "    Saved the Model Weights\n",
    "    Args:\n",
    "        weights: The Weights\n",
    "        weightName: Weight Names\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    weightsFilePath = os.path.join( weightsDirectory, modelName + '.h5' )\n",
    "    theModel.save_weights( weightsFilePath )\n",
    "    \n",
    "    \n",
    "saveModelEverything( theModel, 'JUPYTER_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the stats on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n",
      "Number of Everything\n",
      "UPs: 278\n",
      "DOWNs: 201\n",
      "NAs: 204\n",
      "HOLEs: 218\n"
     ]
    }
   ],
   "source": [
    "print( len( csDM.getListOfDataCSVFileKeys() ) )\n",
    "csDM.reportStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a model with Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from quiver_engine import server\n",
    "\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 480, 640\n",
    "\n",
    "# num_classes = 4\n",
    "\n",
    "def buildModel( numOfNodes=48, numOfLayers=1):\n",
    "    \"\"\"\n",
    "    Builds the basic model.\n",
    "    Returns:\n",
    "        A Keras NN Model\n",
    "\n",
    "    \"\"\"\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 480, 640\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    num_classes = 4\n",
    "\n",
    "    print(\"Building Model with \", numOfNodes, \" nodes and \", numOfLayers, \" layers.\")\n",
    "\n",
    "    theModel = Sequential()\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(5,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=3,\n",
    "               activation='relu',\n",
    "               input_shape=input_shape\n",
    "               )\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(\n",
    "            10,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            activation='relu')\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(Flatten())\n",
    "\n",
    "    for index in range( numOfLayers ):\n",
    "        theModel.add(Dense(numOfNodes))\n",
    "        theModel.add(BatchNormalization())\n",
    "        theModel.add(Activation('relu'))\n",
    "        theModel.add(Dropout(0.25))\n",
    "\n",
    "    theModel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    theModel.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    theModel.summary()\n",
    "    \n",
    "    return theModel\n",
    "    \n",
    "# server.launch(model)\n",
    "\n",
    "# theModel = buildModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = csDM.loadTrainingAndTestDataset( '0', 'IDEPTH' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel( trainingName, theModel, x_train, y_train, x_test, y_test, num_classes=4, numOfEpochs=24 ):\n",
    "    \"\"\"\n",
    "    Trains the model via given data.\n",
    "\n",
    "    Args:\n",
    "        trainingName: A name of this train [mainly to track in TensorBoard\n",
    "        x_train: The X Set for Trainings\n",
    "        y_train: The Y set for Testing\n",
    "        x_test:  The X Set for Training/Verification\n",
    "        y_test:  The Y Set for Testing/Verification\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    img_rows, img_cols = 480, 640\n",
    "    \n",
    "    # Reshape the X sets.\n",
    "    # Mainly for this project.because Keras/Tensor thinks in Channels.\n",
    "    # And since we are using Greyscale data, we really don't have a channel.\n",
    "    # So we have to 'fake' a channel\n",
    "    #\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    # Convert class vectors to binary class matrices\n",
    "    y_train_as_category = to_categorical(y_train, num_classes)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    logFilePath = os.path.join( tensorLogDataDir, trainingName )\n",
    "\n",
    "    TBoardCallback = keras.callbacks.TensorBoard(\n",
    "        log_dir=logFilePath,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "\n",
    "    theModel.fit(x_train,\n",
    "              y_train_as_category,\n",
    "              batch_size=16,\n",
    "              epochs=numOfEpochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test_as_category),\n",
    "              callbacks=[TBoardCallback]\n",
    "              )\n",
    "    \n",
    "    return theModel\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "# X_test = X_test.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train_as_category = to_categorical(y_train, num_classes)\n",
    "# y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "# theModel = trainModel( \"JupyterTESTRUN\", theModel, X_train, Y_train, X_test, Y_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset for Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_Z, Y_test_Z = csDM.loadTestOnlyDataset( '2', 'IDEPTH' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel( theModel, x_test, y_test, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluated the Model.\n",
    "    \n",
    "    Parameters:\n",
    "        theModel:\n",
    "        x_test:\n",
    "        y_test:\n",
    "        num_classes:\n",
    "        \n",
    "    Return:\n",
    "    \n",
    "    \"\"\"\n",
    "    img_rows, img_cols = 480, 640\n",
    "    \n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    score = theModel.evaluate(x_test, y_test_as_category, verbose=0)\n",
    "    print('General > Test loss: ', score[0], 'Test accuracy: ', score[1] )\n",
    "\n",
    "    predictionResults = theModel.predict_classes(x_test, verbose=1)\n",
    "    \n",
    "    scoringList = [0, 0, 0, 0]\n",
    "    scoringListAsPecents = []\n",
    "    \n",
    "    for index in range(len(x_test)):\n",
    "        if( predictionResults[index] == y_test[index] ):\n",
    "#             print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"Match\" )\n",
    "            scoringList[ int(y_test[index]) ] = scoringList[ int(y_test[index]) ] + 1\n",
    "#         else:\n",
    "#             print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"No Match\" )\n",
    "    \n",
    "    for element in scoringList:\n",
    "        scoringListAsPecents.append( element / 10.0 )\n",
    "    \n",
    "#     print( scoringList )\n",
    "        \n",
    "    return { 'SCORE': score, 'SCORELIST' : scoringListAsPecents }\n",
    "\n",
    "\n",
    "# scoringResults = evaluateModel( theModel, X_test, Y_test, 4)\n",
    "# scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "# print(scoringResults['SCORELIST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Human Oracle Part\n",
    "\n",
    "1. Running Training\n",
    "2. Analysize Training with Test Set via Predict()\n",
    "    1. Record Results\n",
    "3. Get the class which got the lowest score from Prediction.\n",
    "    1. Record that Class\n",
    "4. Get 20? Elements of that Class as the Oracle.\n",
    "    1. Record what was added\n",
    "5. Add those new elements into the Training \n",
    "6. Go to Step 1, X Times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HO\n",
      "Building Model with  48  nodes and  1  layers.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 159, 212, 5)       130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 79, 106, 5)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 39, 52, 10)        460       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 19, 26, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4940)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                237168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 196       \n",
      "=================================================================\n",
      "Total params: 238,146\n",
      "Trainable params: 238,050\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/24\n",
      "200/200 [==============================] - 2s - loss: 1.0991 - categorical_accuracy: 0.5500 - val_loss: 1.4904 - val_categorical_accuracy: 0.2750\n",
      "Epoch 2/24\n",
      "200/200 [==============================] - 2s - loss: 0.5865 - categorical_accuracy: 0.7900 - val_loss: 1.4850 - val_categorical_accuracy: 0.2750\n",
      "Epoch 3/24\n",
      "200/200 [==============================] - 2s - loss: 0.4703 - categorical_accuracy: 0.8600 - val_loss: 1.3368 - val_categorical_accuracy: 0.3500\n",
      "Epoch 4/24\n",
      "200/200 [==============================] - 2s - loss: 0.4316 - categorical_accuracy: 0.8600 - val_loss: 1.1702 - val_categorical_accuracy: 0.4500\n",
      "Epoch 5/24\n",
      "200/200 [==============================] - 2s - loss: 0.3656 - categorical_accuracy: 0.8950 - val_loss: 1.1092 - val_categorical_accuracy: 0.7000\n",
      "Epoch 6/24\n",
      "200/200 [==============================] - 2s - loss: 0.2293 - categorical_accuracy: 0.9500 - val_loss: 1.0776 - val_categorical_accuracy: 0.5750\n",
      "Epoch 7/24\n",
      "200/200 [==============================] - 2s - loss: 0.2135 - categorical_accuracy: 0.9750 - val_loss: 1.0216 - val_categorical_accuracy: 0.6000\n",
      "Epoch 8/24\n",
      "200/200 [==============================] - 2s - loss: 0.2198 - categorical_accuracy: 0.9600 - val_loss: 1.0239 - val_categorical_accuracy: 0.6500\n",
      "Epoch 9/24\n",
      "200/200 [==============================] - 2s - loss: 0.1775 - categorical_accuracy: 0.9650 - val_loss: 0.9816 - val_categorical_accuracy: 0.6750\n",
      "Epoch 10/24\n",
      "200/200 [==============================] - 2s - loss: 0.1568 - categorical_accuracy: 0.9800 - val_loss: 1.0286 - val_categorical_accuracy: 0.6750\n",
      "Epoch 11/24\n",
      "200/200 [==============================] - 2s - loss: 0.1242 - categorical_accuracy: 0.9800 - val_loss: 0.9172 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/24\n",
      "200/200 [==============================] - 2s - loss: 0.1019 - categorical_accuracy: 0.9900 - val_loss: 0.8932 - val_categorical_accuracy: 0.7000\n",
      "Epoch 13/24\n",
      "200/200 [==============================] - 2s - loss: 0.1226 - categorical_accuracy: 0.9750 - val_loss: 0.8569 - val_categorical_accuracy: 0.6750\n",
      "Epoch 14/24\n",
      "200/200 [==============================] - 2s - loss: 0.1041 - categorical_accuracy: 0.9800 - val_loss: 0.9980 - val_categorical_accuracy: 0.5250\n",
      "Epoch 15/24\n",
      "200/200 [==============================] - 2s - loss: 0.1004 - categorical_accuracy: 0.9950 - val_loss: 0.8979 - val_categorical_accuracy: 0.6250\n",
      "Epoch 16/24\n",
      "200/200 [==============================] - 2s - loss: 0.0887 - categorical_accuracy: 0.9900 - val_loss: 0.8443 - val_categorical_accuracy: 0.7500\n",
      "Epoch 17/24\n",
      "200/200 [==============================] - 2s - loss: 0.0802 - categorical_accuracy: 0.9850 - val_loss: 0.9783 - val_categorical_accuracy: 0.6250\n",
      "Epoch 18/24\n",
      "200/200 [==============================] - 2s - loss: 0.0925 - categorical_accuracy: 0.9850 - val_loss: 0.8763 - val_categorical_accuracy: 0.6500\n",
      "Epoch 19/24\n",
      "200/200 [==============================] - 2s - loss: 0.0811 - categorical_accuracy: 0.9800 - val_loss: 0.8035 - val_categorical_accuracy: 0.7500\n",
      "Epoch 20/24\n",
      "200/200 [==============================] - 2s - loss: 0.0685 - categorical_accuracy: 0.9950 - val_loss: 0.7790 - val_categorical_accuracy: 0.7250\n",
      "Epoch 21/24\n",
      "200/200 [==============================] - 2s - loss: 0.0559 - categorical_accuracy: 0.9900 - val_loss: 0.7787 - val_categorical_accuracy: 0.7000\n",
      "Epoch 22/24\n",
      "200/200 [==============================] - 2s - loss: 0.0864 - categorical_accuracy: 0.9850 - val_loss: 0.9476 - val_categorical_accuracy: 0.7000\n",
      "Epoch 23/24\n",
      "200/200 [==============================] - 2s - loss: 0.0740 - categorical_accuracy: 0.9950 - val_loss: 0.9267 - val_categorical_accuracy: 0.6500\n",
      "Epoch 24/24\n",
      "200/200 [==============================] - 2s - loss: 0.0663 - categorical_accuracy: 0.9950 - val_loss: 1.0065 - val_categorical_accuracy: 0.6500\n",
      "General > Test loss:  1.13485696316 Test accuracy:  0.675\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1348569631576537, 0.67500000000000004, 0.9, 0.6, 0.8, 0.4, 'HOLE']\n",
      "['HOLE', 15089611530, 15089600111, 15091324491, 15089604121, 15089599230, 15091322481, 15089596420, 15089597471, 15089601760, 15091323631, 15089607671, 15089597531, 15089597591, 15089595680, 15089605591, 15089599351, 15091319031, 15089593610, 15089593540, 15089606390]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 220 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "220/220 [==============================] - 2s - loss: 0.1509 - categorical_accuracy: 0.9409 - val_loss: 0.8098 - val_categorical_accuracy: 0.7250\n",
      "Epoch 2/12\n",
      "220/220 [==============================] - 2s - loss: 0.0908 - categorical_accuracy: 0.9818 - val_loss: 1.2077 - val_categorical_accuracy: 0.5750\n",
      "Epoch 3/12\n",
      "220/220 [==============================] - 2s - loss: 0.0917 - categorical_accuracy: 0.9864 - val_loss: 0.9483 - val_categorical_accuracy: 0.6750\n",
      "Epoch 4/12\n",
      "220/220 [==============================] - 2s - loss: 0.0633 - categorical_accuracy: 0.9864 - val_loss: 1.0147 - val_categorical_accuracy: 0.6250\n",
      "Epoch 5/12\n",
      "220/220 [==============================] - 2s - loss: 0.0748 - categorical_accuracy: 0.9864 - val_loss: 0.7849 - val_categorical_accuracy: 0.7250\n",
      "Epoch 6/12\n",
      "220/220 [==============================] - 2s - loss: 0.0547 - categorical_accuracy: 0.9909 - val_loss: 0.7477 - val_categorical_accuracy: 0.7250\n",
      "Epoch 7/12\n",
      "220/220 [==============================] - 2s - loss: 0.0374 - categorical_accuracy: 1.0000 - val_loss: 0.7770 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "220/220 [==============================] - 2s - loss: 0.0325 - categorical_accuracy: 1.0000 - val_loss: 0.7186 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "220/220 [==============================] - 2s - loss: 0.0358 - categorical_accuracy: 0.9955 - val_loss: 0.7559 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "220/220 [==============================] - 2s - loss: 0.0345 - categorical_accuracy: 0.9955 - val_loss: 0.9762 - val_categorical_accuracy: 0.7000\n",
      "Epoch 11/12\n",
      "220/220 [==============================] - 2s - loss: 0.0268 - categorical_accuracy: 0.9955 - val_loss: 0.8935 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "220/220 [==============================] - 2s - loss: 0.0415 - categorical_accuracy: 0.9909 - val_loss: 0.9725 - val_categorical_accuracy: 0.6750\n",
      "General > Test loss:  1.17958984375 Test accuracy:  0.7\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1795898437500001, 0.69999999999999996, 0.9, 0.6, 0.8, 0.5, 'HOLE']\n",
      "[1.1795898437500001, 0.69999999999999996, 0.9, 0.6, 0.8, 0.5, 'HOLE']\n",
      "['HOLE', 15089603320, 15089594770, 15089596541, 15089605840, 15089600201, 15089595141, 15089601531, 15091322531, 15089605011, 15089607551, 15089598940, 15089604520, 15089600110, 15089596230, 15089601530, 15089597101, 15089597720, 15091323160, 15089607670, 15089601151]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "240/240 [==============================] - 2s - loss: 0.0655 - categorical_accuracy: 0.9833 - val_loss: 1.0524 - val_categorical_accuracy: 0.7000\n",
      "Epoch 2/12\n",
      "240/240 [==============================] - 2s - loss: 0.0438 - categorical_accuracy: 0.9833 - val_loss: 1.1722 - val_categorical_accuracy: 0.6500\n",
      "Epoch 3/12\n",
      "240/240 [==============================] - 2s - loss: 0.0345 - categorical_accuracy: 0.9958 - val_loss: 0.6448 - val_categorical_accuracy: 0.7250\n",
      "Epoch 4/12\n",
      "240/240 [==============================] - 2s - loss: 0.0281 - categorical_accuracy: 0.9958 - val_loss: 0.7147 - val_categorical_accuracy: 0.7750\n",
      "Epoch 5/12\n",
      "240/240 [==============================] - 2s - loss: 0.0521 - categorical_accuracy: 0.9833 - val_loss: 0.7789 - val_categorical_accuracy: 0.7500\n",
      "Epoch 6/12\n",
      "240/240 [==============================] - 2s - loss: 0.0294 - categorical_accuracy: 0.9958 - val_loss: 0.7504 - val_categorical_accuracy: 0.7750\n",
      "Epoch 7/12\n",
      "240/240 [==============================] - 2s - loss: 0.0480 - categorical_accuracy: 0.9917 - val_loss: 0.8135 - val_categorical_accuracy: 0.7000\n",
      "Epoch 8/12\n",
      "240/240 [==============================] - 2s - loss: 0.0280 - categorical_accuracy: 1.0000 - val_loss: 0.8374 - val_categorical_accuracy: 0.6750\n",
      "Epoch 9/12\n",
      "240/240 [==============================] - 2s - loss: 0.0361 - categorical_accuracy: 0.9875 - val_loss: 1.9934 - val_categorical_accuracy: 0.4000\n",
      "Epoch 10/12\n",
      "240/240 [==============================] - 2s - loss: 0.0298 - categorical_accuracy: 0.9958 - val_loss: 1.3275 - val_categorical_accuracy: 0.6750\n",
      "Epoch 11/12\n",
      "240/240 [==============================] - 2s - loss: 0.0234 - categorical_accuracy: 1.0000 - val_loss: 0.9291 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "240/240 [==============================] - 2s - loss: 0.0182 - categorical_accuracy: 1.0000 - val_loss: 0.9928 - val_categorical_accuracy: 0.7500\n",
      "General > Test loss:  1.11715750694 Test accuracy:  0.7\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1171575069427491, 0.69999999999999996, 1.0, 0.6, 0.5, 0.7, 'DOWN']\n",
      "[1.1171575069427491, 0.69999999999999996, 1.0, 0.6, 0.5, 0.7, 'DOWN']\n",
      "['DOWN', 15085991370, 15084365120, 15082667431, 15082660260, 15085994451, 15082676131, 15084377321, 15082676131, 15087883250, 15082669370, 15084364851, 15082667490, 15085985731, 15085993861, 15085993930, 15085988301, 15087884821, 15082661680, 15082661350, 15085986830]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 260 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "260/260 [==============================] - 3s - loss: 0.1908 - categorical_accuracy: 0.9615 - val_loss: 1.4363 - val_categorical_accuracy: 0.6250\n",
      "Epoch 2/12\n",
      "260/260 [==============================] - 3s - loss: 0.1106 - categorical_accuracy: 0.9808 - val_loss: 0.9622 - val_categorical_accuracy: 0.6750\n",
      "Epoch 3/12\n",
      "260/260 [==============================] - 3s - loss: 0.1522 - categorical_accuracy: 0.9500 - val_loss: 1.6884 - val_categorical_accuracy: 0.6000\n",
      "Epoch 4/12\n",
      "260/260 [==============================] - 3s - loss: 0.1180 - categorical_accuracy: 0.9692 - val_loss: 1.4994 - val_categorical_accuracy: 0.6250\n",
      "Epoch 5/12\n",
      "260/260 [==============================] - 3s - loss: 0.0582 - categorical_accuracy: 0.9962 - val_loss: 1.1066 - val_categorical_accuracy: 0.7000\n",
      "Epoch 6/12\n",
      "260/260 [==============================] - 3s - loss: 0.0838 - categorical_accuracy: 0.9885 - val_loss: 1.3488 - val_categorical_accuracy: 0.6500\n",
      "Epoch 7/12\n",
      "260/260 [==============================] - 3s - loss: 0.0512 - categorical_accuracy: 0.9885 - val_loss: 1.1128 - val_categorical_accuracy: 0.6500\n",
      "Epoch 8/12\n",
      "260/260 [==============================] - 3s - loss: 0.0684 - categorical_accuracy: 0.9846 - val_loss: 1.0941 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/12\n",
      "260/260 [==============================] - 3s - loss: 0.0365 - categorical_accuracy: 1.0000 - val_loss: 1.1136 - val_categorical_accuracy: 0.6750\n",
      "Epoch 10/12\n",
      "260/260 [==============================] - 3s - loss: 0.0659 - categorical_accuracy: 0.9846 - val_loss: 1.3664 - val_categorical_accuracy: 0.6750\n",
      "Epoch 11/12\n",
      "260/260 [==============================] - 3s - loss: 0.0370 - categorical_accuracy: 0.9962 - val_loss: 1.2339 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/12\n",
      "260/260 [==============================] - 3s - loss: 0.0357 - categorical_accuracy: 0.9962 - val_loss: 1.1068 - val_categorical_accuracy: 0.7000\n",
      "General > Test loss:  1.53439364433 Test accuracy:  0.775\n",
      "40/40 [==============================] - 0s     \n",
      "[1.5343936443328858, 0.77500000000000002, 1.0, 0.8, 0.9, 0.4, 'HOLE']\n",
      "[1.5343936443328858, 0.77500000000000002, 1.0, 0.8, 0.9, 0.4, 'HOLE']\n",
      "['HOLE', 15089610060, 15089604031, 15089600030, 15089602011, 15089605200, 15091319290, 15089605491, 15089595010, 15089598891, 15089607431, 15089605090, 15089605250, 15089593251, 15089596491, 15089607550, 15089599801, 15089611531, 15089595801, 15089599571, 15089606290]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 280 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "280/280 [==============================] - 3s - loss: 0.1410 - categorical_accuracy: 0.9679 - val_loss: 0.9637 - val_categorical_accuracy: 0.7250\n",
      "Epoch 2/12\n",
      "280/280 [==============================] - 3s - loss: 0.0463 - categorical_accuracy: 0.9893 - val_loss: 1.1001 - val_categorical_accuracy: 0.7250\n",
      "Epoch 3/12\n",
      "280/280 [==============================] - 3s - loss: 0.0630 - categorical_accuracy: 0.9821 - val_loss: 1.8342 - val_categorical_accuracy: 0.6500\n",
      "Epoch 4/12\n",
      "280/280 [==============================] - 3s - loss: 0.0820 - categorical_accuracy: 0.9786 - val_loss: 0.9376 - val_categorical_accuracy: 0.7250\n",
      "Epoch 5/12\n",
      "280/280 [==============================] - 3s - loss: 0.0992 - categorical_accuracy: 0.9571 - val_loss: 0.9473 - val_categorical_accuracy: 0.7750\n",
      "Epoch 6/12\n",
      "280/280 [==============================] - 3s - loss: 0.0512 - categorical_accuracy: 0.9893 - val_loss: 0.9462 - val_categorical_accuracy: 0.7750\n",
      "Epoch 7/12\n",
      "280/280 [==============================] - 3s - loss: 0.0530 - categorical_accuracy: 0.9857 - val_loss: 1.0310 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "280/280 [==============================] - 3s - loss: 0.0655 - categorical_accuracy: 0.9786 - val_loss: 1.9012 - val_categorical_accuracy: 0.6500\n",
      "Epoch 9/12\n",
      "280/280 [==============================] - 3s - loss: 0.0368 - categorical_accuracy: 0.9964 - val_loss: 1.0700 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "280/280 [==============================] - 3s - loss: 0.0405 - categorical_accuracy: 0.9964 - val_loss: 0.9648 - val_categorical_accuracy: 0.7000\n",
      "Epoch 11/12\n",
      "280/280 [==============================] - 3s - loss: 0.0390 - categorical_accuracy: 0.9929 - val_loss: 1.0847 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "280/280 [==============================] - 3s - loss: 0.0241 - categorical_accuracy: 0.9964 - val_loss: 1.2813 - val_categorical_accuracy: 0.7250\n",
      "General > Test loss:  1.53298044205 Test accuracy:  0.7\n",
      "40/40 [==============================] - 0s     \n",
      "[1.5329804420471191, 0.69999999999999996, 0.9, 0.5, 0.9, 0.5, 'UP']\n",
      "[1.5329804420471191, 0.69999999999999996, 0.9, 0.5, 0.9, 0.5, 'UP']\n",
      "['UP', 15084367381, 15082676341, 15082658641, 15085994820, 15087876991, 15082670180, 15085984140, 15084364561, 15082676390, 15087886810, 15087876621, 15082670570, 15085994821, 15082664350, 15084365450, 15082671620, 15082663010, 15085992491, 15085984340, 15084377150]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 300 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "300/300 [==============================] - 3s - loss: 0.1408 - categorical_accuracy: 0.9633 - val_loss: 1.1659 - val_categorical_accuracy: 0.7250\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 3s - loss: 0.0591 - categorical_accuracy: 0.9800 - val_loss: 0.9743 - val_categorical_accuracy: 0.7250\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 3s - loss: 0.0485 - categorical_accuracy: 0.9900 - val_loss: 1.2718 - val_categorical_accuracy: 0.7000\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 3s - loss: 0.0367 - categorical_accuracy: 0.9867 - val_loss: 1.1334 - val_categorical_accuracy: 0.7250\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 3s - loss: 0.0258 - categorical_accuracy: 0.9967 - val_loss: 0.8837 - val_categorical_accuracy: 0.7500\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 3s - loss: 0.0288 - categorical_accuracy: 0.9933 - val_loss: 0.8064 - val_categorical_accuracy: 0.7500\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 3s - loss: 0.0438 - categorical_accuracy: 0.9900 - val_loss: 0.9016 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 3s - loss: 0.0387 - categorical_accuracy: 0.9867 - val_loss: 0.8347 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 3s - loss: 0.0355 - categorical_accuracy: 0.9867 - val_loss: 0.7777 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 3s - loss: 0.0243 - categorical_accuracy: 0.9967 - val_loss: 0.7952 - val_categorical_accuracy: 0.7750\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 3s - loss: 0.0179 - categorical_accuracy: 0.9967 - val_loss: 0.8549 - val_categorical_accuracy: 0.7750\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 3s - loss: 0.0236 - categorical_accuracy: 0.9967 - val_loss: 0.9609 - val_categorical_accuracy: 0.7000\n",
      "General > Test loss:  1.17425739765 Test accuracy:  0.75\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1742573976516724, 0.75, 0.9, 0.8, 0.7, 0.6, 'HOLE']\n",
      "[1.1742573976516724, 0.75, 0.9, 0.8, 0.7, 0.6, 'HOLE']\n",
      "['HOLE', 15089606690, 15089607391, 15089599401, 15091323491, 15089596360, 15089605010, 15089605371, 15089600160, 15089606181, 15089597661, 15089606500, 15089605371, 15089601820, 15089601370, 15089596910, 15089599440, 15089605540, 15089603270, 15089601201, 15089603271]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 320 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "320/320 [==============================] - 3s - loss: 0.0316 - categorical_accuracy: 0.9906 - val_loss: 1.6729 - val_categorical_accuracy: 0.6250\n",
      "Epoch 2/12\n",
      "320/320 [==============================] - 3s - loss: 0.0323 - categorical_accuracy: 0.9812 - val_loss: 3.0421 - val_categorical_accuracy: 0.6000\n",
      "Epoch 3/12\n",
      "320/320 [==============================] - 3s - loss: 0.0348 - categorical_accuracy: 0.9906 - val_loss: 0.7732 - val_categorical_accuracy: 0.7750\n",
      "Epoch 4/12\n",
      "320/320 [==============================] - 3s - loss: 0.0254 - categorical_accuracy: 0.9937 - val_loss: 0.7755 - val_categorical_accuracy: 0.7250\n",
      "Epoch 5/12\n",
      "320/320 [==============================] - 3s - loss: 0.0136 - categorical_accuracy: 0.9969 - val_loss: 0.7700 - val_categorical_accuracy: 0.7250\n",
      "Epoch 6/12\n",
      "320/320 [==============================] - 3s - loss: 0.0111 - categorical_accuracy: 1.0000 - val_loss: 0.7252 - val_categorical_accuracy: 0.7250\n",
      "Epoch 7/12\n",
      "320/320 [==============================] - 3s - loss: 0.0094 - categorical_accuracy: 1.0000 - val_loss: 0.7554 - val_categorical_accuracy: 0.7750\n",
      "Epoch 8/12\n",
      "320/320 [==============================] - 3s - loss: 0.0085 - categorical_accuracy: 1.0000 - val_loss: 0.7465 - val_categorical_accuracy: 0.7750\n",
      "Epoch 9/12\n",
      "320/320 [==============================] - 3s - loss: 0.0130 - categorical_accuracy: 0.9969 - val_loss: 0.7231 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "320/320 [==============================] - 3s - loss: 0.0100 - categorical_accuracy: 1.0000 - val_loss: 0.6951 - val_categorical_accuracy: 0.7500\n",
      "Epoch 11/12\n",
      "320/320 [==============================] - 3s - loss: 0.0272 - categorical_accuracy: 0.9937 - val_loss: 0.6804 - val_categorical_accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "320/320 [==============================] - 3s - loss: 0.0148 - categorical_accuracy: 1.0000 - val_loss: 0.6881 - val_categorical_accuracy: 0.8000\n",
      "General > Test loss:  1.26859016418 Test accuracy:  0.7\n",
      "40/40 [==============================] - 0s     \n",
      "[1.2685901641845703, 0.69999999999999996, 0.9, 0.8, 0.6, 0.5, 'HOLE']\n",
      "[1.2685901641845703, 0.69999999999999996, 0.9, 0.8, 0.6, 0.5, 'HOLE']\n",
      "['HOLE', 15089597721, 15091324061, 15089599111, 15089603681, 15089594950, 15091324241, 15089601261, 15089611350, 15089601901, 15091324060, 15089601640, 15091323310, 15089604290, 15089599880, 15089603900, 15089597530, 15089603530, 15089597470, 15089604340, 15091323370]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 340 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "340/340 [==============================] - 4s - loss: 0.0483 - categorical_accuracy: 0.9941 - val_loss: 0.9381 - val_categorical_accuracy: 0.8000\n",
      "Epoch 2/12\n",
      "340/340 [==============================] - 4s - loss: 0.0241 - categorical_accuracy: 0.9971 - val_loss: 0.8705 - val_categorical_accuracy: 0.7750\n",
      "Epoch 3/12\n",
      "340/340 [==============================] - 4s - loss: 0.0352 - categorical_accuracy: 0.9882 - val_loss: 0.9255 - val_categorical_accuracy: 0.6750\n",
      "Epoch 4/12\n",
      "340/340 [==============================] - 4s - loss: 0.0216 - categorical_accuracy: 0.9941 - val_loss: 1.7621 - val_categorical_accuracy: 0.5750\n",
      "Epoch 5/12\n",
      "340/340 [==============================] - 4s - loss: 0.0539 - categorical_accuracy: 0.9824 - val_loss: 1.2155 - val_categorical_accuracy: 0.7000\n",
      "Epoch 6/12\n",
      "340/340 [==============================] - 4s - loss: 0.0421 - categorical_accuracy: 0.9882 - val_loss: 1.0432 - val_categorical_accuracy: 0.7250\n",
      "Epoch 7/12\n",
      "340/340 [==============================] - 4s - loss: 0.0401 - categorical_accuracy: 0.9912 - val_loss: 2.5195 - val_categorical_accuracy: 0.6000\n",
      "Epoch 8/12\n",
      "340/340 [==============================] - 4s - loss: 0.0944 - categorical_accuracy: 0.9735 - val_loss: 1.8480 - val_categorical_accuracy: 0.6000\n",
      "Epoch 9/12\n",
      "340/340 [==============================] - 4s - loss: 0.0345 - categorical_accuracy: 0.9912 - val_loss: 1.3066 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/12\n",
      "340/340 [==============================] - 4s - loss: 0.0485 - categorical_accuracy: 0.9853 - val_loss: 1.1463 - val_categorical_accuracy: 0.7750\n",
      "Epoch 11/12\n",
      "340/340 [==============================] - 4s - loss: 0.0209 - categorical_accuracy: 0.9971 - val_loss: 0.9938 - val_categorical_accuracy: 0.8000\n",
      "Epoch 12/12\n",
      "340/340 [==============================] - 4s - loss: 0.0280 - categorical_accuracy: 0.9941 - val_loss: 1.2100 - val_categorical_accuracy: 0.7250\n",
      "General > Test loss:  1.34781332165 Test accuracy:  0.675\n",
      "40/40 [==============================] - 0s     \n",
      "[1.3478133216500283, 0.67500000000000004, 1.0, 0.8, 0.3, 0.6, 'DOWN']\n",
      "[1.3478133216500283, 0.67500000000000004, 1.0, 0.8, 0.3, 0.6, 'DOWN']\n",
      "['DOWN', 15082667331, 15087887761, 15084377460, 15084377640, 15082668640, 15087887671, 15085991311, 15084365031, 15084367861, 15082668121, 15082668380, 15087876850, 15085990911, 15085994000, 15085986971, 15084365121, 15085994501, 15082668491, 15085994450, 15082675761]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 360 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "360/360 [==============================] - 4s - loss: 0.1478 - categorical_accuracy: 0.9667 - val_loss: 3.3572 - val_categorical_accuracy: 0.4750\n",
      "Epoch 2/12\n",
      "360/360 [==============================] - 4s - loss: 0.0763 - categorical_accuracy: 0.9750 - val_loss: 1.1601 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/12\n",
      "360/360 [==============================] - 4s - loss: 0.0441 - categorical_accuracy: 0.9889 - val_loss: 0.8559 - val_categorical_accuracy: 0.7750\n",
      "Epoch 4/12\n",
      "360/360 [==============================] - 4s - loss: 0.0502 - categorical_accuracy: 0.9833 - val_loss: 0.8067 - val_categorical_accuracy: 0.8500\n",
      "Epoch 5/12\n",
      "360/360 [==============================] - 4s - loss: 0.0422 - categorical_accuracy: 0.9917 - val_loss: 1.0529 - val_categorical_accuracy: 0.7250\n",
      "Epoch 6/12\n",
      "360/360 [==============================] - 4s - loss: 0.0234 - categorical_accuracy: 0.9972 - val_loss: 0.7384 - val_categorical_accuracy: 0.7750\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 [==============================] - 4s - loss: 0.0224 - categorical_accuracy: 0.9944 - val_loss: 0.8638 - val_categorical_accuracy: 0.7750\n",
      "Epoch 8/12\n",
      "360/360 [==============================] - 4s - loss: 0.0375 - categorical_accuracy: 0.9861 - val_loss: 0.9279 - val_categorical_accuracy: 0.8000\n",
      "Epoch 9/12\n",
      "360/360 [==============================] - 4s - loss: 0.0199 - categorical_accuracy: 1.0000 - val_loss: 0.8215 - val_categorical_accuracy: 0.7750\n",
      "Epoch 10/12\n",
      "360/360 [==============================] - 4s - loss: 0.0624 - categorical_accuracy: 0.9778 - val_loss: 1.1381 - val_categorical_accuracy: 0.7250\n",
      "Epoch 11/12\n",
      "360/360 [==============================] - 4s - loss: 0.0590 - categorical_accuracy: 0.9889 - val_loss: 0.8631 - val_categorical_accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "360/360 [==============================] - 4s - loss: 0.0494 - categorical_accuracy: 0.9778 - val_loss: 0.9295 - val_categorical_accuracy: 0.7250\n",
      "General > Test loss:  1.22370752096 Test accuracy:  0.675\n",
      "40/40 [==============================] - 0s     \n",
      "[1.2237075209617614, 0.67500000000000004, 0.9, 0.8, 0.4, 0.6, 'DOWN']\n",
      "[1.2237075209617614, 0.67500000000000004, 0.9, 0.8, 0.4, 0.6, 'DOWN']\n",
      "['DOWN', 15085985780, 15085989601, 15087879680, 15084375610, 15087884891, 15085987160, 15087883210, 15085989270, 15085988390, 15082668260, 15085993670, 15082669291, 15085994001, 15082675710, 15087878110, 15082661230, 15082669550, 15084375610, 15084367791, 15082667491]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 380 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "380/380 [==============================] - 4s - loss: 0.0998 - categorical_accuracy: 0.9816 - val_loss: 1.4166 - val_categorical_accuracy: 0.6750\n",
      "Epoch 2/12\n",
      "380/380 [==============================] - 4s - loss: 0.0517 - categorical_accuracy: 0.9842 - val_loss: 0.7525 - val_categorical_accuracy: 0.7250\n",
      "Epoch 3/12\n",
      "380/380 [==============================] - 4s - loss: 0.0308 - categorical_accuracy: 0.9921 - val_loss: 1.5387 - val_categorical_accuracy: 0.6250\n",
      "Epoch 4/12\n",
      "380/380 [==============================] - 4s - loss: 0.0372 - categorical_accuracy: 0.9895 - val_loss: 1.0953 - val_categorical_accuracy: 0.8000\n",
      "Epoch 5/12\n",
      "380/380 [==============================] - 4s - loss: 0.0214 - categorical_accuracy: 0.9947 - val_loss: 1.2442 - val_categorical_accuracy: 0.7000\n",
      "Epoch 6/12\n",
      "380/380 [==============================] - 4s - loss: 0.0422 - categorical_accuracy: 0.9895 - val_loss: 0.9519 - val_categorical_accuracy: 0.7250\n",
      "Epoch 7/12\n",
      "380/380 [==============================] - 4s - loss: 0.0203 - categorical_accuracy: 0.9974 - val_loss: 0.9932 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "380/380 [==============================] - 4s - loss: 0.0123 - categorical_accuracy: 1.0000 - val_loss: 0.9179 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "380/380 [==============================] - 4s - loss: 0.0219 - categorical_accuracy: 0.9947 - val_loss: 1.0914 - val_categorical_accuracy: 0.7000\n",
      "Epoch 10/12\n",
      "380/380 [==============================] - 4s - loss: 0.0231 - categorical_accuracy: 0.9974 - val_loss: 1.2191 - val_categorical_accuracy: 0.7250\n",
      "Epoch 11/12\n",
      "380/380 [==============================] - 4s - loss: 0.0111 - categorical_accuracy: 0.9974 - val_loss: 1.0028 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "380/380 [==============================] - 4s - loss: 0.0128 - categorical_accuracy: 1.0000 - val_loss: 1.0237 - val_categorical_accuracy: 0.7500\n",
      "General > Test loss:  0.999745577574 Test accuracy:  0.725\n",
      "40/40 [==============================] - 0s     \n",
      "[0.99974557757377625, 0.72499999999999998, 0.9, 0.6, 0.7, 0.7, 'UP']\n",
      "[0.99974557757377625, 0.72499999999999998, 0.9, 0.6, 0.7, 0.7, 'UP']\n",
      "['UP', 15087877061, 15082667050, 15082667860, 15087887431, 15087886931, 15084364110, 15084364410, 15085994881, 15087883931, 15087880350, 15087877921, 15087882720, 15087887001, 15087887000, 15082676441, 15082665381, 15082665651, 15085991800, 15087883060, 15087882860]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 400 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "400/400 [==============================] - 5s - loss: 0.0889 - categorical_accuracy: 0.9725 - val_loss: 2.9479 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/12\n",
      "400/400 [==============================] - 4s - loss: 0.0424 - categorical_accuracy: 0.9875 - val_loss: 1.5718 - val_categorical_accuracy: 0.6750\n",
      "Epoch 3/12\n",
      "400/400 [==============================] - 4s - loss: 0.0470 - categorical_accuracy: 0.9850 - val_loss: 1.3205 - val_categorical_accuracy: 0.7250\n",
      "Epoch 4/12\n",
      "400/400 [==============================] - 4s - loss: 0.0200 - categorical_accuracy: 0.9950 - val_loss: 1.9899 - val_categorical_accuracy: 0.6500\n",
      "Epoch 5/12\n",
      "400/400 [==============================] - 4s - loss: 0.0153 - categorical_accuracy: 0.9975 - val_loss: 1.7859 - val_categorical_accuracy: 0.6750\n",
      "Epoch 6/12\n",
      "400/400 [==============================] - 4s - loss: 0.0232 - categorical_accuracy: 0.9925 - val_loss: 0.9324 - val_categorical_accuracy: 0.7500\n",
      "Epoch 7/12\n",
      "400/400 [==============================] - 4s - loss: 0.0315 - categorical_accuracy: 0.9875 - val_loss: 1.8923 - val_categorical_accuracy: 0.6250\n",
      "Epoch 8/12\n",
      "400/400 [==============================] - 4s - loss: 0.0165 - categorical_accuracy: 0.9950 - val_loss: 0.9337 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "400/400 [==============================] - 4s - loss: 0.0183 - categorical_accuracy: 0.9950 - val_loss: 0.9210 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "400/400 [==============================] - 4s - loss: 0.0139 - categorical_accuracy: 0.9975 - val_loss: 1.5920 - val_categorical_accuracy: 0.6000\n",
      "Epoch 11/12\n",
      "400/400 [==============================] - 4s - loss: 0.0188 - categorical_accuracy: 0.9950 - val_loss: 1.3938 - val_categorical_accuracy: 0.6250\n",
      "Epoch 12/12\n",
      "400/400 [==============================] - 4s - loss: 0.0246 - categorical_accuracy: 0.9925 - val_loss: 0.8355 - val_categorical_accuracy: 0.8250\n",
      "General > Test loss:  1.13449817896 Test accuracy:  0.8\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1344981789588928, 0.80000000000000004, 0.9, 0.9, 0.6, 0.8, 'DOWN']\n",
      "[1.1344981789588928, 0.80000000000000004, 0.9, 0.9, 0.6, 0.8, 'DOWN']\n",
      "['DOWN', 15085985381, 15106037540, 15085989470, 15082668560, 15082660141, 15084375540, 15085991310, 15085991441, 15085991310, 15106037480, 15082659700, 15082661751, 15085994071, 15082660141, 15085994071, 15085985080, 15082661681, 15084375680, 15082669460, 15082669181]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 420 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "420/420 [==============================] - 5s - loss: 0.1216 - categorical_accuracy: 0.9690 - val_loss: 0.9653 - val_categorical_accuracy: 0.6750\n",
      "Epoch 2/12\n",
      "420/420 [==============================] - 4s - loss: 0.0924 - categorical_accuracy: 0.9738 - val_loss: 2.5150 - val_categorical_accuracy: 0.6250\n",
      "Epoch 3/12\n",
      "420/420 [==============================] - 5s - loss: 0.0745 - categorical_accuracy: 0.9643 - val_loss: 1.0274 - val_categorical_accuracy: 0.7000\n",
      "Epoch 4/12\n",
      "420/420 [==============================] - 4s - loss: 0.0572 - categorical_accuracy: 0.9833 - val_loss: 1.4971 - val_categorical_accuracy: 0.7000\n",
      "Epoch 5/12\n",
      "420/420 [==============================] - 5s - loss: 0.0360 - categorical_accuracy: 0.9929 - val_loss: 1.1123 - val_categorical_accuracy: 0.6750\n",
      "Epoch 6/12\n",
      "420/420 [==============================] - 4s - loss: 0.0652 - categorical_accuracy: 0.9833 - val_loss: 1.3358 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/12\n",
      "420/420 [==============================] - 4s - loss: 0.0569 - categorical_accuracy: 0.9762 - val_loss: 1.1735 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "420/420 [==============================] - 5s - loss: 0.0524 - categorical_accuracy: 0.9833 - val_loss: 1.3516 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/12\n",
      "420/420 [==============================] - 4s - loss: 0.0317 - categorical_accuracy: 0.9881 - val_loss: 1.6021 - val_categorical_accuracy: 0.6500\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 [==============================] - 4s - loss: 0.0536 - categorical_accuracy: 0.9881 - val_loss: 1.5216 - val_categorical_accuracy: 0.6750\n",
      "Epoch 11/12\n",
      "420/420 [==============================] - 4s - loss: 0.0361 - categorical_accuracy: 0.9833 - val_loss: 1.0235 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/12\n",
      "420/420 [==============================] - 4s - loss: 0.0420 - categorical_accuracy: 0.9857 - val_loss: 1.6420 - val_categorical_accuracy: 0.6250\n",
      "General > Test loss:  1.47214346528 Test accuracy:  0.675\n",
      "40/40 [==============================] - 0s     \n",
      "[1.4721434652805327, 0.67500000000000004, 0.9, 0.4, 0.7, 0.7, 'UP']\n",
      "[1.4721434652805327, 0.67500000000000004, 0.9, 0.4, 0.7, 0.7, 'UP']\n",
      "['UP', 15084365621, 15084367211, 15087877661, 15084364411, 15085991901, 15087882920, 15087879431, 15087885611, 15084375041, 15082671230, 15085995190, 15084364481, 15082666961, 15087888671, 15084372191, 15084376181, 15085988821, 15082670311, 15087882641, 15084367210]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 440 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "440/440 [==============================] - 5s - loss: 0.1375 - categorical_accuracy: 0.9614 - val_loss: 1.5879 - val_categorical_accuracy: 0.6000\n",
      "Epoch 2/12\n",
      "440/440 [==============================] - 5s - loss: 0.0983 - categorical_accuracy: 0.9636 - val_loss: 1.2932 - val_categorical_accuracy: 0.6250\n",
      "Epoch 3/12\n",
      "440/440 [==============================] - 5s - loss: 0.0461 - categorical_accuracy: 0.9886 - val_loss: 1.3381 - val_categorical_accuracy: 0.6750\n",
      "Epoch 4/12\n",
      "440/440 [==============================] - 5s - loss: 0.0685 - categorical_accuracy: 0.9773 - val_loss: 0.9534 - val_categorical_accuracy: 0.7250\n",
      "Epoch 5/12\n",
      "440/440 [==============================] - 5s - loss: 0.0727 - categorical_accuracy: 0.9795 - val_loss: 1.2324 - val_categorical_accuracy: 0.7250\n",
      "Epoch 6/12\n",
      "440/440 [==============================] - 5s - loss: 0.0280 - categorical_accuracy: 0.9932 - val_loss: 1.3097 - val_categorical_accuracy: 0.6750\n",
      "Epoch 7/12\n",
      "440/440 [==============================] - 5s - loss: 0.0442 - categorical_accuracy: 0.9886 - val_loss: 1.2823 - val_categorical_accuracy: 0.6750\n",
      "Epoch 8/12\n",
      "440/440 [==============================] - 5s - loss: 0.0391 - categorical_accuracy: 0.9841 - val_loss: 1.3221 - val_categorical_accuracy: 0.6500\n",
      "Epoch 9/12\n",
      "440/440 [==============================] - 5s - loss: 0.0446 - categorical_accuracy: 0.9955 - val_loss: 1.0159 - val_categorical_accuracy: 0.6500\n",
      "Epoch 10/12\n",
      "440/440 [==============================] - 5s - loss: 0.0337 - categorical_accuracy: 0.9909 - val_loss: 1.2387 - val_categorical_accuracy: 0.6250\n",
      "Epoch 11/12\n",
      "440/440 [==============================] - 5s - loss: 0.0368 - categorical_accuracy: 0.9841 - val_loss: 1.5519 - val_categorical_accuracy: 0.6000\n",
      "Epoch 12/12\n",
      "440/440 [==============================] - 5s - loss: 0.0292 - categorical_accuracy: 0.9909 - val_loss: 1.0689 - val_categorical_accuracy: 0.6500\n",
      "General > Test loss:  1.21411091089 Test accuracy:  0.75\n",
      "40/40 [==============================] - 0s     \n",
      "[1.2141109108924866, 0.75, 0.8, 0.8, 0.7, 0.7, 'DOWN']\n",
      "[1.2141109108924866, 0.75, 0.8, 0.8, 0.7, 0.7, 'DOWN']\n",
      "['DOWN', 15082670920, 15082676081, 15084368240, 15082661040, 15085988080, 15085985140, 15087879810, 15082670741, 15085985140, 15106037710, 15087888430, 15087881750, 15084368240, 15106037710, 15087880861, 15085988221, 15084377320, 15087888430, 15085984770, 15085988981]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 460 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "460/460 [==============================] - 5s - loss: 0.0936 - categorical_accuracy: 0.9804 - val_loss: 1.1648 - val_categorical_accuracy: 0.7750\n",
      "Epoch 2/12\n",
      "460/460 [==============================] - 5s - loss: 0.0716 - categorical_accuracy: 0.9804 - val_loss: 1.4441 - val_categorical_accuracy: 0.7250\n",
      "Epoch 3/12\n",
      "460/460 [==============================] - 5s - loss: 0.0314 - categorical_accuracy: 0.9935 - val_loss: 1.2904 - val_categorical_accuracy: 0.6750\n",
      "Epoch 4/12\n",
      "460/460 [==============================] - 5s - loss: 0.0332 - categorical_accuracy: 0.9913 - val_loss: 1.5765 - val_categorical_accuracy: 0.6250\n",
      "Epoch 5/12\n",
      "460/460 [==============================] - 5s - loss: 0.0279 - categorical_accuracy: 0.9913 - val_loss: 1.4063 - val_categorical_accuracy: 0.6500\n",
      "Epoch 6/12\n",
      "460/460 [==============================] - 5s - loss: 0.0397 - categorical_accuracy: 0.9957 - val_loss: 1.2126 - val_categorical_accuracy: 0.6500\n",
      "Epoch 7/12\n",
      "460/460 [==============================] - 5s - loss: 0.0166 - categorical_accuracy: 0.9935 - val_loss: 1.0379 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "460/460 [==============================] - 5s - loss: 0.0245 - categorical_accuracy: 0.9935 - val_loss: 1.2947 - val_categorical_accuracy: 0.6750\n",
      "Epoch 9/12\n",
      "460/460 [==============================] - 5s - loss: 0.0374 - categorical_accuracy: 0.9891 - val_loss: 1.1853 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/12\n",
      "460/460 [==============================] - 5s - loss: 0.0381 - categorical_accuracy: 0.9891 - val_loss: 1.3148 - val_categorical_accuracy: 0.7750\n",
      "Epoch 11/12\n",
      "460/460 [==============================] - 5s - loss: 0.0298 - categorical_accuracy: 0.9891 - val_loss: 1.2640 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "460/460 [==============================] - 5s - loss: 0.0590 - categorical_accuracy: 0.9804 - val_loss: 1.1758 - val_categorical_accuracy: 0.7750\n",
      "General > Test loss:  0.990941482782 Test accuracy:  0.825\n",
      "40/40 [==============================] - 0s     \n",
      "[0.99094148278236394, 0.82499999999999996, 0.9, 0.9, 0.7, 0.8, 'DOWN']\n",
      "[0.99094148278236394, 0.82499999999999996, 0.9, 0.9, 0.7, 0.8, 'DOWN']\n",
      "['DOWN', 15082659701, 15084365030, 15082660261, 15082660800, 15082661430, 15084377691, 15087876741, 15087887841, 15085991500, 15085989121, 15082661571, 15084375280, 15085989600, 15084376561, 15087884481, 15082668190, 15087876741, 15082660800, 15085985661, 15084376710]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 480 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "480/480 [==============================] - 5s - loss: 0.0790 - categorical_accuracy: 0.9812 - val_loss: 2.7207 - val_categorical_accuracy: 0.6250\n",
      "Epoch 2/12\n",
      "480/480 [==============================] - 5s - loss: 0.0280 - categorical_accuracy: 0.9937 - val_loss: 1.4466 - val_categorical_accuracy: 0.7500\n",
      "Epoch 3/12\n",
      "480/480 [==============================] - 5s - loss: 0.0354 - categorical_accuracy: 0.9854 - val_loss: 1.1322 - val_categorical_accuracy: 0.7000\n",
      "Epoch 4/12\n",
      "480/480 [==============================] - 5s - loss: 0.0366 - categorical_accuracy: 0.9875 - val_loss: 1.2347 - val_categorical_accuracy: 0.6500\n",
      "Epoch 5/12\n",
      "480/480 [==============================] - 5s - loss: 0.0315 - categorical_accuracy: 0.9917 - val_loss: 1.2501 - val_categorical_accuracy: 0.6750\n",
      "Epoch 6/12\n",
      "480/480 [==============================] - 5s - loss: 0.0210 - categorical_accuracy: 0.9917 - val_loss: 1.2387 - val_categorical_accuracy: 0.6750\n",
      "Epoch 7/12\n",
      "480/480 [==============================] - 5s - loss: 0.0566 - categorical_accuracy: 0.9833 - val_loss: 1.1564 - val_categorical_accuracy: 0.7250\n",
      "Epoch 8/12\n",
      "480/480 [==============================] - 5s - loss: 0.0338 - categorical_accuracy: 0.9875 - val_loss: 1.1913 - val_categorical_accuracy: 0.7500\n",
      "Epoch 9/12\n",
      "480/480 [==============================] - 5s - loss: 0.0158 - categorical_accuracy: 0.9958 - val_loss: 0.9718 - val_categorical_accuracy: 0.7500\n",
      "Epoch 10/12\n",
      "480/480 [==============================] - 5s - loss: 0.0392 - categorical_accuracy: 0.9854 - val_loss: 1.5976 - val_categorical_accuracy: 0.6500\n",
      "Epoch 11/12\n",
      "480/480 [==============================] - 5s - loss: 0.0231 - categorical_accuracy: 0.9937 - val_loss: 1.4131 - val_categorical_accuracy: 0.6750\n",
      "Epoch 12/12\n",
      "480/480 [==============================] - 5s - loss: 0.0311 - categorical_accuracy: 0.9854 - val_loss: 1.4003 - val_categorical_accuracy: 0.6000\n",
      "General > Test loss:  1.21123266816 Test accuracy:  0.75\n",
      "40/40 [==============================] - 0s     \n",
      "[1.2112326681613923, 0.75, 0.9, 0.7, 0.8, 0.6, 'HOLE']\n",
      "[1.2112326681613923, 0.75, 0.9, 0.7, 0.8, 0.6, 'HOLE']\n",
      "['HOLE', 15091324191, 15089596981, 15089603371, 15089595871, 15091322730, 15089595331, 15089605420, 15089593380, 15089597660, 15089606691, 15089599231, 15089599800, 15089603220, 15089610391, 15089595211, 15089611270, 15089595940, 15091322670, 15089597660, 15089596361]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "500/500 [==============================] - 5s - loss: 0.0635 - categorical_accuracy: 0.9820 - val_loss: 1.6791 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/12\n",
      "500/500 [==============================] - 5s - loss: 0.0452 - categorical_accuracy: 0.9840 - val_loss: 2.3106 - val_categorical_accuracy: 0.5500\n",
      "Epoch 3/12\n",
      "500/500 [==============================] - 5s - loss: 0.0611 - categorical_accuracy: 0.9840 - val_loss: 1.6033 - val_categorical_accuracy: 0.6000\n",
      "Epoch 4/12\n",
      "500/500 [==============================] - 5s - loss: 0.0347 - categorical_accuracy: 0.9860 - val_loss: 1.3715 - val_categorical_accuracy: 0.6750\n",
      "Epoch 5/12\n",
      "500/500 [==============================] - 5s - loss: 0.0566 - categorical_accuracy: 0.9720 - val_loss: 3.1713 - val_categorical_accuracy: 0.5500\n",
      "Epoch 6/12\n",
      "500/500 [==============================] - 5s - loss: 0.0542 - categorical_accuracy: 0.9780 - val_loss: 1.3589 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/12\n",
      "500/500 [==============================] - 5s - loss: 0.0515 - categorical_accuracy: 0.9840 - val_loss: 1.6767 - val_categorical_accuracy: 0.6000\n",
      "Epoch 8/12\n",
      "500/500 [==============================] - 5s - loss: 0.0479 - categorical_accuracy: 0.9860 - val_loss: 1.3274 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/12\n",
      "500/500 [==============================] - 5s - loss: 0.0366 - categorical_accuracy: 0.9880 - val_loss: 1.1152 - val_categorical_accuracy: 0.6750\n",
      "Epoch 10/12\n",
      "500/500 [==============================] - 5s - loss: 0.0198 - categorical_accuracy: 0.9940 - val_loss: 1.4069 - val_categorical_accuracy: 0.7250\n",
      "Epoch 11/12\n",
      "500/500 [==============================] - 5s - loss: 0.0141 - categorical_accuracy: 0.9960 - val_loss: 1.2677 - val_categorical_accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "500/500 [==============================] - 5s - loss: 0.0400 - categorical_accuracy: 0.9900 - val_loss: 1.2708 - val_categorical_accuracy: 0.6750\n",
      "General > Test loss:  1.07480875775 Test accuracy:  0.825\n",
      "40/40 [==============================] - 0s     \n",
      "[1.0748087577521801, 0.82499999999999996, 1.0, 0.7, 0.7, 0.9, 'UP']\n",
      "[1.0748087577521801, 0.82499999999999996, 1.0, 0.7, 0.7, 0.9, 'UP']\n",
      "['UP', 15084365390, 15085987860, 15082671140, 15082661901, 15087888820, 15087880081, 15087884011, 15085987861, 15085987931, 15087877801, 15082663110, 15082667240, 15082667940, 15085995070, 15084364330, 15087887501, 15082670100, 15084367440, 15085990000, 15087877801]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 520 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "520/520 [==============================] - 6s - loss: 0.1285 - categorical_accuracy: 0.9731 - val_loss: 1.3868 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/12\n",
      "520/520 [==============================] - 6s - loss: 0.0543 - categorical_accuracy: 0.9808 - val_loss: 1.7457 - val_categorical_accuracy: 0.6000\n",
      "Epoch 3/12\n",
      "520/520 [==============================] - 5s - loss: 0.0325 - categorical_accuracy: 0.9904 - val_loss: 1.2210 - val_categorical_accuracy: 0.7250\n",
      "Epoch 4/12\n",
      "520/520 [==============================] - 6s - loss: 0.0445 - categorical_accuracy: 0.9865 - val_loss: 0.9702 - val_categorical_accuracy: 0.7500\n",
      "Epoch 5/12\n",
      "520/520 [==============================] - 5s - loss: 0.0315 - categorical_accuracy: 0.9904 - val_loss: 1.0833 - val_categorical_accuracy: 0.7000\n",
      "Epoch 6/12\n",
      "520/520 [==============================] - 6s - loss: 0.0296 - categorical_accuracy: 0.9923 - val_loss: 1.0460 - val_categorical_accuracy: 0.7000\n",
      "Epoch 7/12\n",
      "520/520 [==============================] - 6s - loss: 0.0360 - categorical_accuracy: 0.9885 - val_loss: 1.3528 - val_categorical_accuracy: 0.6500\n",
      "Epoch 8/12\n",
      "520/520 [==============================] - 6s - loss: 0.0260 - categorical_accuracy: 0.9962 - val_loss: 1.0517 - val_categorical_accuracy: 0.7000\n",
      "Epoch 9/12\n",
      "520/520 [==============================] - 6s - loss: 0.0338 - categorical_accuracy: 0.9885 - val_loss: 0.8293 - val_categorical_accuracy: 0.7750\n",
      "Epoch 10/12\n",
      "520/520 [==============================] - 6s - loss: 0.0208 - categorical_accuracy: 0.9942 - val_loss: 0.9776 - val_categorical_accuracy: 0.7750\n",
      "Epoch 11/12\n",
      "520/520 [==============================] - 6s - loss: 0.0186 - categorical_accuracy: 0.9923 - val_loss: 1.0157 - val_categorical_accuracy: 0.7500\n",
      "Epoch 12/12\n",
      "520/520 [==============================] - 6s - loss: 0.0382 - categorical_accuracy: 0.9865 - val_loss: 1.0522 - val_categorical_accuracy: 0.6750\n",
      "General > Test loss:  1.10750722885 Test accuracy:  0.775\n",
      "40/40 [==============================] - 0s     \n",
      "[1.1075072288513184, 0.77500000000000002, 0.8, 0.9, 0.7, 0.7, 'DOWN']\n",
      "[1.1075072288513184, 0.77500000000000002, 0.8, 0.9, 0.7, 0.7, 'DOWN']\n",
      "['DOWN', 15084377391, 15082666821, 15082661231, 15084367641, 15082676181, 15082669180, 15082659221, 15082668641, 15085984941, 15087881751, 15085988150, 15087884550, 15087884721, 15084375611, 15082661750, 15087883470, 15087878160, 15082660871, 15082676181, 15082660871]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 540 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "540/540 [==============================] - 6s - loss: 0.0692 - categorical_accuracy: 0.9852 - val_loss: 2.2084 - val_categorical_accuracy: 0.5750\n",
      "Epoch 2/12\n",
      "540/540 [==============================] - 6s - loss: 0.0249 - categorical_accuracy: 0.9889 - val_loss: 1.2056 - val_categorical_accuracy: 0.6750\n",
      "Epoch 3/12\n",
      "540/540 [==============================] - 6s - loss: 0.0378 - categorical_accuracy: 0.9833 - val_loss: 1.4646 - val_categorical_accuracy: 0.6250\n",
      "Epoch 4/12\n",
      "540/540 [==============================] - 6s - loss: 0.0339 - categorical_accuracy: 0.9907 - val_loss: 1.0221 - val_categorical_accuracy: 0.7500\n",
      "Epoch 5/12\n",
      "540/540 [==============================] - 6s - loss: 0.0331 - categorical_accuracy: 0.9833 - val_loss: 1.8934 - val_categorical_accuracy: 0.5750\n",
      "Epoch 6/12\n",
      "540/540 [==============================] - 6s - loss: 0.0475 - categorical_accuracy: 0.9815 - val_loss: 4.0117 - val_categorical_accuracy: 0.4750\n",
      "Epoch 7/12\n",
      "540/540 [==============================] - 6s - loss: 0.0289 - categorical_accuracy: 0.9907 - val_loss: 3.0712 - val_categorical_accuracy: 0.6000\n",
      "Epoch 8/12\n",
      "540/540 [==============================] - 6s - loss: 0.0251 - categorical_accuracy: 0.9907 - val_loss: 1.2852 - val_categorical_accuracy: 0.7250\n",
      "Epoch 9/12\n",
      "540/540 [==============================] - 6s - loss: 0.0248 - categorical_accuracy: 0.9907 - val_loss: 1.0075 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/12\n",
      "540/540 [==============================] - 6s - loss: 0.0130 - categorical_accuracy: 0.9963 - val_loss: 1.1569 - val_categorical_accuracy: 0.6250\n",
      "Epoch 11/12\n",
      "540/540 [==============================] - 6s - loss: 0.0190 - categorical_accuracy: 0.9926 - val_loss: 0.9134 - val_categorical_accuracy: 0.7250\n",
      "Epoch 12/12\n",
      "540/540 [==============================] - 6s - loss: 0.0199 - categorical_accuracy: 0.9926 - val_loss: 0.9915 - val_categorical_accuracy: 0.7000\n",
      "General > Test loss:  0.897607290745 Test accuracy:  0.85\n",
      "40/40 [==============================] - 0s     \n",
      "[0.89760729074478152, 0.84999999999999998, 0.9, 0.9, 0.7, 0.9, 'DOWN']\n",
      "[0.89760729074478152, 0.84999999999999998, 0.9, 0.9, 0.7, 0.9, 'DOWN']\n",
      "['DOWN', 15106037601, 15085993730, 15082659870, 15087883391, 15082670740, 15087881821, 15085994271, 15087880810, 15082660651, 15082669690, 15087887931, 15082660740, 15082659451, 15082667571, 15085991440, 15082659541, 15085985730, 15087880810, 15085994270, 15082660331]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 560 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "560/560 [==============================] - 6s - loss: 0.0304 - categorical_accuracy: 0.9911 - val_loss: 1.0783 - val_categorical_accuracy: 0.6750\n",
      "Epoch 2/12\n",
      "560/560 [==============================] - 6s - loss: 0.0237 - categorical_accuracy: 0.9929 - val_loss: 1.6895 - val_categorical_accuracy: 0.6500\n",
      "Epoch 3/12\n",
      "560/560 [==============================] - 6s - loss: 0.0569 - categorical_accuracy: 0.9732 - val_loss: 1.2637 - val_categorical_accuracy: 0.7500\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/560 [==============================] - 6s - loss: 0.0464 - categorical_accuracy: 0.9821 - val_loss: 1.4735 - val_categorical_accuracy: 0.6750\n",
      "Epoch 5/12\n",
      "560/560 [==============================] - 6s - loss: 0.0249 - categorical_accuracy: 0.9911 - val_loss: 1.3535 - val_categorical_accuracy: 0.6750\n",
      "Epoch 6/12\n",
      "560/560 [==============================] - 6s - loss: 0.0133 - categorical_accuracy: 0.9946 - val_loss: 1.1607 - val_categorical_accuracy: 0.6500\n",
      "Epoch 7/12\n",
      "560/560 [==============================] - 6s - loss: 0.0235 - categorical_accuracy: 0.9857 - val_loss: 0.9707 - val_categorical_accuracy: 0.7750\n",
      "Epoch 8/12\n",
      "560/560 [==============================] - 6s - loss: 0.0194 - categorical_accuracy: 0.9929 - val_loss: 0.8673 - val_categorical_accuracy: 0.7750\n",
      "Epoch 9/12\n",
      "560/560 [==============================] - 6s - loss: 0.0202 - categorical_accuracy: 0.9893 - val_loss: 0.9591 - val_categorical_accuracy: 0.7250\n",
      "Epoch 10/12\n",
      "560/560 [==============================] - 6s - loss: 0.0198 - categorical_accuracy: 0.9946 - val_loss: 0.9263 - val_categorical_accuracy: 0.7500\n",
      "Epoch 11/12\n",
      "560/560 [==============================] - 6s - loss: 0.0250 - categorical_accuracy: 0.9946 - val_loss: 1.7447 - val_categorical_accuracy: 0.6000\n",
      "Epoch 12/12\n",
      "560/560 [==============================] - 6s - loss: 0.0205 - categorical_accuracy: 0.9911 - val_loss: 1.9827 - val_categorical_accuracy: 0.6250\n",
      "General > Test loss:  1.56042265892 Test accuracy:  0.7\n",
      "40/40 [==============================] - 0s     \n",
      "[1.5604226589202881, 0.69999999999999996, 0.9, 0.4, 0.8, 0.7, 'UP']\n",
      "[1.5604226589202881, 0.69999999999999996, 0.9, 0.4, 0.8, 0.7, 'UP']\n",
      "['UP', 15082664831, 15082671421, 15087879430, 15087887271, 15087883061, 15084365860, 15106028321, 15087876410, 15087883010, 15087884081, 15085990231, 15082663501, 15087877721, 15087883871, 15087885181, 15087880290, 15087883011, 15085995440, 15084365720, 15084375990]\n",
      "/Users/staque/Development/GitHub/CS-660-Semester-Project-V2/ANACONDA/../DATA/COMBINED/IDEPTH\n",
      "Train on 580 samples, validate on 40 samples\n",
      "Epoch 1/12\n",
      "144/580 [======>.......................] - ETA: 5s - loss: 0.1860 - categorical_accuracy: 0.9653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0c565da466b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;31m# elementsAddedToTrainingSetFileName = getElementsAddedToTrainingSetFileName()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m \u001b[0mrunHumanOracle\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnumberOfAges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-0c565da466b7>\u001b[0m in \u001b[0;36mrunHumanOracle\u001b[0;34m(numberOfAges)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# And Then we train the model again.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mstringOfTheAge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'JupyterHumanOracleTraining_AGE_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstringOfTheAge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9b258635bf99>\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(trainingName, theModel, x_train, y_train, x_test, y_test, num_classes, numOfEpochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_as_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTBoardCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m               )\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def runHumanOracle( numberOfAges=20 ):\n",
    "    \"\"\"\n",
    "    Human Oracle master function\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting HO\")\n",
    "    \n",
    "    # Starting\n",
    "    numberOfEachClass = {'UP':556, 'DOWN': 402, 'NA':408, 'HOLE': 436 }\n",
    "    \n",
    "    # After Train/Test removed.\n",
    "    numberOfEachClass = {'UP':496, 'DOWN': 342, 'NA':348, 'HOLE': 376 }\n",
    "    \n",
    "    # What are re analysizing.\n",
    "    dataFlavor = 'IDEPTH'\n",
    "    \n",
    "    # First get the file name we need to record data.\n",
    "    trainingPredictionResultsFileName = hO.getTrainingPredictionResultsFileName()\n",
    "    elementsAddedToTrainingSetFileName = hO.getElementsAddedToTrainingSetFileName()\n",
    "    \n",
    "    # Get Elements to train and test on\n",
    "    X_train, Y_train, X_test, Y_test , X_trainList, Y_TestList = csDM.loadTrainingAndTestDatasetAndLists( '0', dataFlavor )\n",
    "    \n",
    "    # This is to ensure our test set always stay independent.\n",
    "    allTestListsCombined = hO.getAllTestLists()\n",
    "    \n",
    "    # Get Independent Set for Testing \n",
    "    # Techincally the above X_test, Y_test, should be indepedent, according to the Keras documentation.\n",
    "    # But I am using a second set just because.\n",
    "    X_test_Z, Y_test_Z = csDM.loadTestOnlyDataset( '2', dataFlavor )\n",
    "    \n",
    "    # Build Model\n",
    "    theModel = buildModel()\n",
    "        \n",
    "    # Train the Model\n",
    "    trainModel( \"JupyterHumanOracleTraining\", theModel, X_train, Y_train, X_test, Y_test, 4)\n",
    "        \n",
    "    # Evaluate the Model [with indie data]\n",
    "    scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "\n",
    "    # Now the real Fun starts.\n",
    "    # Get Lowest scoring class.\n",
    "    lowestScoringClassName = csDM.getClassFromNumeral( hO.getLowestScoringCategory( scoringResults['SCORELIST'] ) )\n",
    "\n",
    "    # Record the Init Results of the first eval and the first lowest scoring category.\n",
    "    hO.recordTrainingPredictionResults( trainingPredictionResultsFileName, scoringResults, lowestScoringClassName )\n",
    "\n",
    "    for index in range(numberOfAges):\n",
    "\n",
    "        # Get new samples from the lowest scoring class.\n",
    "        newSamples = hO.getSamplesFromAClass( lowestScoringClassName, X_trainList, allTestListsCombined, 20 )    \n",
    "\n",
    "        # Subtract newSamples to makes sure we have samples to work with\n",
    "        \n",
    "        \n",
    "        # Record What we added.\n",
    "        hO.recordElementsAddedToTrainingSet( elementsAddedToTrainingSetFileName, lowestScoringClassName, newSamples )\n",
    "\n",
    "        X_trainList = X_trainList + newSamples\n",
    "        \n",
    "        # Add samples to training set\n",
    "        # NOTE: We need to turn the 'newSamples' into NPArrays.  It is these new NP Arrays we add to \n",
    "        # X_train, Y_train.  Out Original List of the what is in the training sets stay intact.\n",
    "\n",
    "        # So first get the NPArrays of the new Samples\n",
    "        dictOfLearningAndVerificationNPArrays = csDM.createNPArraysFor( newSamples, dataFlavor )\n",
    "\n",
    "        # Then we add them to the training set.\n",
    "        \n",
    "#         print(type(X_train))\n",
    "#         print(type(dictOfLearningAndVerificationNPArrays['LEARNING']))\n",
    "        \n",
    "#         print( X_train.shape )\n",
    "#         print( dictOfLearningAndVerificationNPArrays['LEARNING'].shape )\n",
    "        \n",
    "        \n",
    "        X_train = np.concatenate( (X_train, dictOfLearningAndVerificationNPArrays['LEARNING']), axis=0 )\n",
    "        Y_train = np.concatenate( (Y_train, dictOfLearningAndVerificationNPArrays['VERIFICATION']), axis=0 )\n",
    "\n",
    "        # And Then we train the model again.\n",
    "        stringOfTheAge = 'JupyterHumanOracleTraining_AGE_' + str(index)\n",
    "        trainModel( stringOfTheAge, theModel, X_train, Y_train, X_test, Y_test, 4, 12)\n",
    "        \n",
    "        \n",
    "        # Evaluate the Model [with indie data]\n",
    "        scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "\n",
    "        # Now the real Fun starts.\n",
    "        # Get Lowest scoring class.\n",
    "        lowestScoringClassName = csDM.getClassFromNumeral( hO.getLowestScoringCategory( scoringResults['SCORELIST'] ) )\n",
    "\n",
    "        # Record the Init Results of the first eval and the first lowest scoring category.\n",
    "        hO.recordTrainingPredictionResults( trainingPredictionResultsFileName, scoringResults, lowestScoringClassName )\n",
    "\n",
    "    \n",
    "    \n",
    "# def getElementsAddedToTrainingSetFileName():\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     theFileName = 'JUPYTER_ADDED_ELEMENTS_RECORD' + csDM.getDateTimeAsString() + '.txt'\n",
    "#     return theFileName\n",
    "\n",
    "\n",
    "# def getTrainingPredictionResultsFileName():\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     theFileName = 'JUPYTER_TRAIN_PREDICTION_RESULTS' + csDM.getDateTimeAsString() + '.txt'\n",
    "#     return theFileName\n",
    "\n",
    "\n",
    "    \n",
    "# def recordElementsAddedToTrainingSet( currentFileName, nameOfClassAdded, elementsList ):\n",
    "#     \"\"\"\n",
    "#     Record the Training and Predictions Results.\n",
    "#     \"\"\"\n",
    "#     trainingPredictionResultsPath = os.path.join(resultsDirectory, currentFileName )\n",
    "\n",
    "#     classAndElements = []\n",
    "#     classAndElements.append(nameOfClassAdded)\n",
    "#     classAndElements = classAndElements + elementsList\n",
    "    \n",
    "#     print(classAndElements)\n",
    "    \n",
    "#     with open(trainingPredictionResultsPath, 'a', newline='\\n') as csvfile:\n",
    "#         csvWriter = csv.writer(\n",
    "#             csvfile, \n",
    "#             delimiter=','\n",
    "#         )\n",
    "#         csvWriter.writerow( classAndElements )\n",
    "\n",
    "            \n",
    "# def recordTrainingPredictionResults( currentFileName, scoringResults, lowestScoringClassName ):\n",
    "#     \"\"\"\n",
    "#     Record the Training and Predictions Results.\n",
    "#     \"\"\"\n",
    "#     trainingPredictionResultsPath = os.path.join(resultsDirectory, currentFileName)\n",
    "#     allScoringInfo = scoringResults['SCORE'] + scoringResults['SCORELIST']\n",
    "#     allScoringInfo.append(lowestScoringClassName)\n",
    "    \n",
    "#     print(allScoringInfo)\n",
    "    \n",
    "#     if( not os.path.exists( trainingPredictionResultsPath) ):\n",
    "#         headers = ['TestLoss', 'TestAccuracy', 'NA', 'UP', 'DOWN', 'HOLE']\n",
    "#         with open(trainingPredictionResultsPath, 'w', newline='\\n') as csvfile:\n",
    "#             csvWriter = csv.writer(\n",
    "#                 csvfile, \n",
    "#                 delimiter=','\n",
    "#             )\n",
    "#             csvWriter.writerow( headers )\n",
    "#             csvWriter.writerow( allScoringInfo )\n",
    "            \n",
    "#     else:\n",
    "#         print(allScoringInfo)\n",
    "#         with open(trainingPredictionResultsPath, 'a', newline='\\n') as csvfile:\n",
    "#             csvWriter = csv.writer(\n",
    "#                 csvfile, \n",
    "#                 delimiter=','\n",
    "#             )\n",
    "#             csvWriter.writerow( allScoringInfo )\n",
    "\n",
    "\n",
    "# def reportOracle( status ):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     oracleReportPath = os.path.join(resultsDirectory, 'JUPYTER_ORACLE_REPORT.txt')\n",
    "#     fileToWrite = open(oracleReportPath, 'a')\n",
    "#     fileToWrite.write( status + '\\n' )\n",
    "#     fileToWrite.close()\n",
    "\n",
    "\n",
    "# def getLowestScoringCategory( scoringListAsPecents ):\n",
    "#     \"\"\"\n",
    "#     Get the index of the lowest scoring category.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     lowestCategoryPercent = 1.0\n",
    "#     currentLowestIndex = 0\n",
    "    \n",
    "#     for index in range(len(scoringListAsPecents)):\n",
    "#         currentCategoryPercent = scoringListAsPecents[index]\n",
    "#         if( currentCategoryPercent < lowestCategoryPercent ):\n",
    "#             currentLowestIndex = index\n",
    "#             lowestCategoryPercent = currentCategoryPercent\n",
    "\n",
    "#     return currentLowestIndex\n",
    "\n",
    "\n",
    "# def addNewSamplesToTrainingSet( trainingList, newSamples ):\n",
    "#     \"\"\"\n",
    "#     Merge the new samples with the Training set.\n",
    "#     \"\"\"\n",
    "#     return trainingList + newSamples\n",
    "    \n",
    "\n",
    "# def getSamplesFromAClass( classType, trainingList, allTestListsCombined, numberOfSamples=20 ):\n",
    "#     \"\"\"\n",
    "#     Get multiple samples from a class.\n",
    "#     \"\"\"\n",
    "#     newSamples = []\n",
    "    \n",
    "#     for index in range(numberOfSamples):\n",
    "#         newSample = getASampleOfClass( classType, trainingList, allTestListsCombined )\n",
    "#         newSamples.append( newSample )\n",
    "\n",
    "#     return newSamples\n",
    "        \n",
    "\n",
    "# def getASampleOfClass( classType, trainingList, allTestListsCombined ):\n",
    "#     \"\"\"\n",
    "#     Get a Sample from a Specific class that isn't being trained on yet.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     classTypeToRetreive = ''\n",
    "    \n",
    "#     if( classType == 'UP' ):\n",
    "#         classTypeToRetreive = 'upList'\n",
    "#     elif( classType == 'DOWN' ):\n",
    "#         classTypeToRetreive = 'downList'\n",
    "#     elif( classType == 'NA' ):\n",
    "#         classTypeToRetreive = 'naList'\n",
    "#     elif( classType == 'HOLE' ):\n",
    "#         classTypeToRetreive = 'holeList'\n",
    "        \n",
    "#     random.seed( datetime.datetime.utcnow() )\n",
    "    \n",
    "#     dataClassList = csDM.getDictOfClassLists()\n",
    "    \n",
    "#     trainingListAsSet = set( trainingList )\n",
    "#     allTestListsCombinedAsSet = set( allTestListsCombined )\n",
    "    \n",
    "#     allElementsOfClass = dataClassList[classTypeToRetreive]\n",
    "    \n",
    "#     selectedSample = random.choice(allElementsOfClass)\n",
    "    \n",
    "#     while( ( selectedSample in trainingListAsSet) or ( selectedSample in allTestListsCombinedAsSet) ):\n",
    "#         selectedSample = random.choice(allElementsOfClass)\n",
    "\n",
    "#     return selectedSample\n",
    "    \n",
    "\n",
    "# def getAllTestLists():\n",
    "#     \"\"\"\n",
    "#     Gets all the test lists.\n",
    "#     Returns:\n",
    "#         A Dict of the test lists.\n",
    "#     \"\"\"\n",
    "#     allTestLists = []\n",
    "#     allTestListCombined = []\n",
    "    \n",
    "#     for index in range(5):\n",
    "#         allTestLists.append( csDM.getTestList(index) )\n",
    "#         allTestListCombined = allTestListCombined + csDM.getTestList(index)\n",
    "        \n",
    "#     return { 'TestLists' : allTestLists, 'CombinedTestLists' : allTestListCombined}\n",
    "\n",
    "# dataClassList = csDM.getDictOfClassLists()\n",
    "# allTheTestLists = getAllTestLists()\n",
    "# theTrainingList = csDM.getTrainingList(0)\n",
    "\n",
    "# print( len( allTheTestLists['TestLists'] ), len( allTheTestLists['CombinedTestLists'] ), len(theTrainingList) )\n",
    "# print(\"\")\n",
    "\n",
    "\n",
    "# lowestCategory = csDM.getClassFromNumeral(getLowestScoringCategory(scoringResults['SCORELIST']))\n",
    "# newTrainingSet = getSamplesFromAClass( lowestCategory, theTrainingList, allTheTestLists['CombinedTestLists'], 20 )\n",
    "# combinedTrainingAndNewSampleList = addNewSamplesToTrainingSet( theTrainingList, newTrainingSet )\n",
    "\n",
    "# print(len(combinedTrainingAndNewSampleList))\n",
    "# print(getLowestScoringCategory(scoringResults['SCORELIST']))\n",
    "# print(lowestCategory)\n",
    "\n",
    "# print(\"\")\n",
    "# print(newTrainingSet)\n",
    "\n",
    "# trainingPredictionResultsFileName = getTrainingPredictionResultsFileName()\n",
    "# elementsAddedToTrainingSetFileName = getElementsAddedToTrainingSetFileName()\n",
    "\n",
    "runHumanOracle( numberOfAges=20 )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
