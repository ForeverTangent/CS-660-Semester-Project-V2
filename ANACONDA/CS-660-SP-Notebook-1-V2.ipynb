{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-660 Semester Project Notebook 1\n",
    "\n",
    "## Stan Rosenbaum\n",
    "\n",
    "Fall 2017\n",
    "\n",
    "Anaconda 5 / Python 3\n",
    "\n",
    "Using Keras with TensorFlow as back end.\n",
    "\n",
    "### Background Important Stuff\n",
    "\n",
    "First the Enums of the Classes\n",
    "\n",
    "* \"NA\" = 0\n",
    "* \"UP\" = 1\n",
    "* \"DOWN\" = 2\n",
    "* \"HOLE\" = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS660DataManagementCheck Imported\n"
     ]
    }
   ],
   "source": [
    "# First we init stuff.\n",
    "# Load the Basic Python Libraries\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "# Load my Data Management Module\n",
    "import CS660DataManagement as csDM\n",
    "import HumanOracle as hO\n",
    "\n",
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Load Keras Stuff\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "# Other.  Mostly Graphic stuff for displaying Data in and out of Jupyter.\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Not using Quiver Yet.\n",
    "# from quiver_engine import server\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Processed Data Directory.\n",
    "processedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PROCESSED' )\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "pickleDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PICKLES' )\n",
    "modelsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS' )\n",
    "modelsStructsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS_STRUCTS' )\n",
    "weightsDirectory = os.path.join( os.getcwd(), os.pardir, 'WEIGHTS' )\n",
    "resultsDirectory = os.path.join( os.getcwd(), os.pardir, 'RESULTS' )\n",
    "\n",
    "testImageColorFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'ICOLOR', 'TEST.png' )\n",
    "testImageDepthFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'IDEPTH', 'TEST.png' )\n",
    "testCSVFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'PCLOUD', 'TEST.csv' )\n",
    "\n",
    "tensorLogDataDir = os.path.join( os.getcwd(), os.pardir, 'TENSOR_LOGS' )\n",
    "\n",
    "imageDirs = ['ICOLOR', 'IDEPTH']\n",
    "csvDirs = ['PCLOUD']\n",
    "\n",
    "allDataFlavors = imageDirs + csvDirs\n",
    "\n",
    "#Load main data file.\n",
    "searCSVInfoFile = os.path.join( combinedDataDir, 'SEAR_DC_INFO.csv' )\n",
    "\n",
    "csDM.CS660DataManagementCheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model Data\n",
    "\n",
    "Unless we need to train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Loaded.\n"
     ]
    }
   ],
   "source": [
    "def loadModel( modelName ):\n",
    "    \"\"\"\n",
    "    Loads the Model.\n",
    "    \"\"\"\n",
    "    theModel = load_model( os.path.join( modelsDirectory, modelName) )\n",
    "    print('MODEL Loaded.')\n",
    "    return theModel\n",
    "\n",
    "\n",
    "theModel = loadModel( 'JUPYTER_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Everything Saved\n"
     ]
    }
   ],
   "source": [
    "def saveModelEverything( theModel, modelName ):\n",
    "    \"\"\"\n",
    "    Saved Everything in regards to the model.\n",
    "    \"\"\"\n",
    "    saveModelStructure( theModel, modelName )\n",
    "    saveModel( theModel, modelName )\n",
    "    saveModelJSON( theModel, modelName )\n",
    "    saveModelWeights( theModel, modelName )\n",
    "    \n",
    "    print(\"Model Everything Saved\")\n",
    "    \n",
    "\n",
    "def saveModelStructure( theModel, modelStructureName ):\n",
    "    \"\"\"\n",
    "    Saves an image of the Model Structure.\n",
    "    \"\"\"\n",
    "    modelStructsFilePath = os.path.join(modelsStructsDirectory, modelStructureName )\n",
    "    plot_model(theModel, to_file=modelStructsFilePath)\n",
    "\n",
    "\n",
    "def saveModelJSON( model, modelName ):\n",
    "    \"\"\"\n",
    "    Saves the Model as JSON\n",
    "    Args:\n",
    "        model: the Keras NN Model\n",
    "        modelName: the Name\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    modelFilePath = os.path.join( modelsDirectory, modelName + '.json' )\n",
    "    model_json = theModel.to_json()\n",
    "    with open( modelFilePath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "        \n",
    "def saveModel( model, modelName ):\n",
    "    \"\"\"\n",
    "    Save the model, in Keras [h5] format.\n",
    "    \"\"\"\n",
    "    theModel.save(os.path.join( modelsDirectory, modelName ))\n",
    "\n",
    "    \n",
    "def saveModelWeights( theModel, modelName ):\n",
    "    \"\"\"\n",
    "    Saved the Model Weights\n",
    "    Args:\n",
    "        weights: The Weights\n",
    "        weightName: Weight Names\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    weightsFilePath = os.path.join( weightsDirectory, modelName + '.h5' )\n",
    "    theModel.save_weights( weightsFilePath )\n",
    "    \n",
    "    \n",
    "saveModelEverything( theModel, 'JUPYTER_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the stats on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n",
      "Number of Everything\n",
      "UPs: 278\n",
      "DOWNs: 201\n",
      "NAs: 204\n",
      "HOLEs: 218\n"
     ]
    }
   ],
   "source": [
    "print( len( csDM.getListOfDataCSVFileKeys() ) )\n",
    "csDM.reportStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a model with Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from quiver_engine import server\n",
    "\n",
    "# input image dimensions\n",
    "# img_rows, img_cols = 480, 640\n",
    "\n",
    "# num_classes = 4\n",
    "\n",
    "def buildModel( numOfNodes=48, numOfLayers=1):\n",
    "    \"\"\"\n",
    "    Builds the basic model.\n",
    "    Returns:\n",
    "        A Keras NN Model\n",
    "\n",
    "    \"\"\"\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 480, 640\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    num_classes = 4\n",
    "\n",
    "    print(\"Building Model with \", numOfNodes, \" nodes and \", numOfLayers, \" layers.\")\n",
    "\n",
    "    theModel = Sequential()\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(5,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=3,\n",
    "               activation='relu',\n",
    "               input_shape=input_shape\n",
    "               )\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(\n",
    "            10,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            activation='relu')\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(Flatten())\n",
    "\n",
    "    for index in range( numOfLayers ):\n",
    "        theModel.add(Dense(numOfNodes))\n",
    "        theModel.add(BatchNormalization())\n",
    "        theModel.add(Activation('relu'))\n",
    "        theModel.add(Dropout(0.25))\n",
    "\n",
    "    theModel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    theModel.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    theModel.summary()\n",
    "    \n",
    "    return theModel\n",
    "    \n",
    "# server.launch(model)\n",
    "\n",
    "# theModel = buildModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = csDM.loadTrainingAndTestDataset( '0', 'IDEPTH' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel( trainingName, theModel, x_train, y_train, x_test, y_test, num_classes=4, numOfEpochs=24 ):\n",
    "    \"\"\"\n",
    "    Trains the model via given data.\n",
    "\n",
    "    Args:\n",
    "        trainingName: A name of this train [mainly to track in TensorBoard\n",
    "        x_train: The X Set for Trainings\n",
    "        y_train: The Y set for Testing\n",
    "        x_test:  The X Set for Training/Verification\n",
    "        y_test:  The Y Set for Testing/Verification\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    img_rows, img_cols = 480, 640\n",
    "    \n",
    "    # Reshape the X sets.\n",
    "    # Mainly for this project.because Keras/Tensor thinks in Channels.\n",
    "    # And since we are using Greyscale data, we really don't have a channel.\n",
    "    # So we have to 'fake' a channel\n",
    "    #\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    # Convert class vectors to binary class matrices\n",
    "    y_train_as_category = to_categorical(y_train, num_classes)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    logFilePath = os.path.join( tensorLogDataDir, trainingName )\n",
    "\n",
    "    TBoardCallback = keras.callbacks.TensorBoard(\n",
    "        log_dir=logFilePath,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "\n",
    "    theModel.fit(x_train,\n",
    "              y_train_as_category,\n",
    "              batch_size=16,\n",
    "              epochs=numOfEpochs,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test_as_category),\n",
    "              callbacks=[TBoardCallback]\n",
    "              )\n",
    "    \n",
    "    return theModel\n",
    "\n",
    "\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "# X_test = X_test.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train_as_category = to_categorical(y_train, num_classes)\n",
    "# y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "# theModel = trainModel( \"JupyterTESTRUN\", theModel, X_train, Y_train, X_test, Y_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset for Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_Z, Y_test_Z = csDM.loadTestOnlyDataset( '2', 'IDEPTH' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel( theModel, x_test, y_test, num_classes):\n",
    "    \"\"\"\n",
    "    Evaluated the Model.\n",
    "    \n",
    "    Parameters:\n",
    "        theModel:\n",
    "        x_test:\n",
    "        y_test:\n",
    "        num_classes:\n",
    "        \n",
    "    Return:\n",
    "    \n",
    "    \"\"\"\n",
    "    img_rows, img_cols = 480, 640\n",
    "    \n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    score = theModel.evaluate(x_test, y_test_as_category, verbose=0)\n",
    "    print('General > Test loss: ', score[0], 'Test accuracy: ', score[1] )\n",
    "\n",
    "    predictionResults = theModel.predict_classes(x_test, verbose=1)\n",
    "    \n",
    "    scoringList = [0, 0, 0, 0]\n",
    "    scoringListAsPecents = []\n",
    "    \n",
    "    for index in range(len(x_test)):\n",
    "        if( predictionResults[index] == y_test[index] ):\n",
    "#             print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"Match\" )\n",
    "            scoringList[ int(y_test[index]) ] = scoringList[ int(y_test[index]) ] + 1\n",
    "#         else:\n",
    "#             print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"No Match\" )\n",
    "    \n",
    "    for element in scoringList:\n",
    "        scoringListAsPecents.append( element / 10.0 )\n",
    "    \n",
    "#     print( scoringList )\n",
    "        \n",
    "    return { 'SCORE': score, 'SCORELIST' : scoringListAsPecents }\n",
    "\n",
    "\n",
    "# scoringResults = evaluateModel( theModel, X_test, Y_test, 4)\n",
    "# scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "# print(scoringResults['SCORELIST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Human Oracle Part\n",
    "\n",
    "1. Running Training\n",
    "2. Analysize Training with Test Set via Predict()\n",
    "    1. Record Results\n",
    "3. Get the class which got the lowest score from Prediction.\n",
    "    1. Record that Class\n",
    "4. Get 20? Elements of that Class as the Oracle.\n",
    "    1. Record what was added\n",
    "5. Add those new elements into the Training \n",
    "6. Go to Step 1, X Times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def runHumanOracle( numberOfAges=20 ):\n",
    "    \"\"\"\n",
    "    Human Oracle master function\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Starting HO\")\n",
    "    \n",
    "    # Starting\n",
    "    numberOfEachClass = {'UP':556, 'DOWN': 402, 'NA':408, 'HOLE': 436 }\n",
    "    \n",
    "    # After Train/Test removed.\n",
    "    numberOfEachClass = {'UP':496, 'DOWN': 342, 'NA':348, 'HOLE': 376 }\n",
    "    \n",
    "    # What are re analysizing.\n",
    "    dataFlavor = 'IDEPTH'\n",
    "    \n",
    "    # First get the file name we need to record data.\n",
    "    trainingPredictionResultsFileName = hO.getTrainingPredictionResultsFileName()\n",
    "    elementsAddedToTrainingSetFileName = hO.getElementsAddedToTrainingSetFileName()\n",
    "    \n",
    "    # Get Elements to train and test on\n",
    "    X_train, Y_train, X_test, Y_test , X_trainList, Y_TestList = csDM.loadTrainingAndTestDatasetAndLists( '0', dataFlavor )\n",
    "    \n",
    "    # This is to ensure our test set always stay independent.\n",
    "    allTestListsCombined = hO.getAllTestLists()\n",
    "    \n",
    "    # Get Independent Set for Testing \n",
    "    # Techincally the above X_test, Y_test, should be indepedent, according to the Keras documentation.\n",
    "    # But I am using a second set just because.\n",
    "    X_test_Z, Y_test_Z = csDM.loadTestOnlyDataset( '2', dataFlavor )\n",
    "    \n",
    "    # Build Model\n",
    "    theModel = buildModel()\n",
    "        \n",
    "    # Train the Model\n",
    "    trainModel( \"JupyterHumanOracleTraining\", theModel, X_train, Y_train, X_test, Y_test, 4)\n",
    "        \n",
    "    # Evaluate the Model [with indie data]\n",
    "    scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "\n",
    "    # Now the real Fun starts.\n",
    "    # Get Lowest scoring class.\n",
    "    lowestScoringClassName = csDM.getClassFromNumeral( hO.getLowestScoringCategory( scoringResults['SCORELIST'] ) )\n",
    "\n",
    "    # Record the Init Results of the first eval and the first lowest scoring category.\n",
    "    hO.recordTrainingPredictionResults( trainingPredictionResultsFileName, scoringResults, lowestScoringClassName )\n",
    "\n",
    "    for index in range(numberOfAges):\n",
    "\n",
    "        # Get new samples from the lowest scoring class.\n",
    "        newSamples = hO.getSamplesFromAClass( lowestScoringClassName, X_trainList, allTestListsCombined, 20 )    \n",
    "\n",
    "        # Subtract newSamples to makes sure we have samples to work with\n",
    "        \n",
    "        \n",
    "        # Record What we added.\n",
    "        hO.recordElementsAddedToTrainingSet( elementsAddedToTrainingSetFileName, lowestScoringClassName, newSamples )\n",
    "\n",
    "        X_trainList = X_trainList + newSamples\n",
    "        \n",
    "        # Add samples to training set\n",
    "        # NOTE: We need to turn the 'newSamples' into NPArrays.  It is these new NP Arrays we add to \n",
    "        # X_train, Y_train.  Out Original List of the what is in the training sets stay intact.\n",
    "\n",
    "        # So first get the NPArrays of the new Samples\n",
    "        dictOfLearningAndVerificationNPArrays = csDM.createNPArraysFor( newSamples, dataFlavor )\n",
    "\n",
    "        # Then we add them to the training set.\n",
    "        \n",
    "#         print(type(X_train))\n",
    "#         print(type(dictOfLearningAndVerificationNPArrays['LEARNING']))\n",
    "        \n",
    "#         print( X_train.shape )\n",
    "#         print( dictOfLearningAndVerificationNPArrays['LEARNING'].shape )\n",
    "        \n",
    "        \n",
    "        X_train = np.concatenate( (X_train, dictOfLearningAndVerificationNPArrays['LEARNING']), axis=0 )\n",
    "        Y_train = np.concatenate( (Y_train, dictOfLearningAndVerificationNPArrays['VERIFICATION']), axis=0 )\n",
    "\n",
    "        # And Then we train the model again.\n",
    "        stringOfTheAge = 'JupyterHumanOracleTraining_AGE_' + str(index)\n",
    "        trainModel( stringOfTheAge, theModel, X_train, Y_train, X_test, Y_test, 4, 12)\n",
    "        \n",
    "        \n",
    "        # Evaluate the Model [with indie data]\n",
    "        scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "\n",
    "        # Now the real Fun starts.\n",
    "        # Get Lowest scoring class.\n",
    "        lowestScoringClassName = csDM.getClassFromNumeral( hO.getLowestScoringCategory( scoringResults['SCORELIST'] ) )\n",
    "\n",
    "        # Record the Init Results of the first eval and the first lowest scoring category.\n",
    "        hO.recordTrainingPredictionResults( trainingPredictionResultsFileName, scoringResults, lowestScoringClassName )\n",
    "\n",
    "\n",
    "# runHumanOracle( numberOfAges=20 )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Generate Plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (16,) and (13,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ef4e73f7b169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mgeneratePlotsInResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-ef4e73f7b169>\u001b[0m in \u001b[0;36mgeneratePlotsInResults\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mHOLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxAxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b*-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxAxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rs:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxAxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gp:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3316\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3317\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3318\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3319\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (16,) and (13,)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "resultsDirectory = os.path.join( os.getcwd(), os.pardir, 'RESULTS' )\n",
    "resultPlotsDirectory = os.path.join( os.getcwd(), os.pardir, 'RESULTS_PLOTS' )\n",
    "\n",
    "rootString = 'PyCHARM_TRAIN_PREDICTION_RESULTS'\n",
    "\n",
    "TestLoss = []\n",
    "TestAccuracy = []\n",
    "NA = []\n",
    "UP = []\n",
    "DOWN = []\n",
    "HOLE = []\n",
    "\n",
    "xAxis = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "headers = ['TestLoss','TestAccuracy','NA','UP','DOWN','HOLE']\n",
    "\n",
    "def generatePlotsInResults():\n",
    "    listFromDir = os.listdir( resultsDirectory )\n",
    "    for element in listFromDir:\n",
    "        if(rootString in element):\n",
    "            pathToOpen = os.path.join( resultsDirectory, element )\n",
    "            with open( pathToOpen, newline='\\n') as csvFile:\n",
    "                csvReader = csv.reader( csvFile, delimiter=',')\n",
    "                for row in csvReader:\n",
    "                    if row[1] in headers:\n",
    "                        pass\n",
    "                    else:\n",
    "                        TestLoss.append(float(row[0]))\n",
    "                        TestAccuracy.append(float(row[1]))\n",
    "                        NA.append(float(row[2]))\n",
    "                        UP.append(float(row[3]))\n",
    "                        DOWN.append(float(row[4]))\n",
    "                        HOLE.append(float(row[5]))\n",
    "                        \n",
    "            plt.plot(xAxis, TestAccuracy, 'b*-')\n",
    "            plt.plot(xAxis, NA, 'rs:')\n",
    "            plt.plot(xAxis, UP, 'gp:')\n",
    "            plt.plot(xAxis, DOWN, 'c^:')\n",
    "            plt.plot(xAxis, HOLE, 'mh:')\n",
    "            \n",
    "            plt.xlabel('AGE')\n",
    "            \n",
    "            saveFileName = element + '.png'\n",
    "            savePath = os.path.join( resultPlotsDirectory, saveFileName ) \n",
    "            plt.savefig(savePath)\n",
    "\n",
    "            TestLoss.clear()\n",
    "            TestAccuracy.clear()\n",
    "            NA.clear()\n",
    "            UP.clear()\n",
    "            DOWN.clear()\n",
    "            HOLE.clear()\n",
    "            \n",
    "            plt.clf()\n",
    "            \n",
    "            \n",
    "generatePlotsInResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
