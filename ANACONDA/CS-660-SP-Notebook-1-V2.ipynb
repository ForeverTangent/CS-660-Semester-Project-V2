{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-660 Semester Project Notebook 1\n",
    "\n",
    "## Stan Rosenbaum\n",
    "\n",
    "Fall 2017\n",
    "\n",
    "Anaconda 5 / Python 3\n",
    "\n",
    "Using Keras with TensorFlow as back end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we init stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS660DataManagementCheck Imported\n"
     ]
    }
   ],
   "source": [
    "# Load the Basic Python Libraries\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Load my Data Management Module\n",
    "import CS660DataManagement as csDM\n",
    "\n",
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Load Keras Studd\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "# Other\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "# Not sure what this is:\n",
    "# from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Processed Data Directory.\n",
    "processedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PROCESSED' )\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "pickleDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PICKLES' )\n",
    "\n",
    "testImageColorFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'ICOLOR', 'TEST.png' )\n",
    "testImageDepthFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'IDEPTH', 'TEST.png' )\n",
    "testCSVFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'PCLOUD', 'TEST.csv' )\n",
    "\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "\n",
    "imageDirs = ['ICOLOR', 'IDEPTH']\n",
    "csvDirs = ['PCLOUD']\n",
    "\n",
    "allDataFlavors = imageDirs + csvDirs\n",
    "\n",
    "#Load main data file.\n",
    "searCSVInfoFile = os.path.join( combinedDataDir, 'SEAR_DC_INFO.csv' )\n",
    "\n",
    "csDM.CS660DataManagementCheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Learning and Verification sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n",
      "Number of Everything\n",
      "UPs: 278\n",
      "DOWNs: 201\n",
      "NAs: 204\n",
      "HOLEs: 218\n"
     ]
    }
   ],
   "source": [
    "print( len( csDM.getListOfDataCSVFileKeys() ) )\n",
    "csDM.reportStats()\n",
    "#csDM.createLearningAndVerificationPickles()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Training Set.\n",
    "#### (Basing this all on the Coursera Course Code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 480, 640)\n",
      "0.682352941176\n",
      "number of training examples = 200\n",
      "number of test examples = 40\n",
      "(40, 480, 640, 1)\n",
      "[ 0.68235294]\n",
      "X_train shape: (200, 480, 640, 1)\n",
      "Y_train shape: (200, 1)\n",
      "y_train_binary shape: (200, 4)\n",
      "X_test shape: (40, 480, 640, 1)\n",
      "Y_test shape: (40, 1)\n",
      "y_test_binary shape: (40, 4)\n"
     ]
    }
   ],
   "source": [
    "# def reshape(trainingSet):\n",
    "#     \"\"\"\n",
    "#     This is to add the 'Channels' Dimension for Keras.\n",
    "#     \"\"\"\n",
    "#     getShape = trainingSet.shape\n",
    "#     newShape = getShape + (1,)\n",
    "#     return trainingSet.reshape(newShape)\n",
    "    \n",
    "\n",
    "# X_train, Y_train, X_test, Y_test = csDM.load_dataset( '1', 'ICOLOR' )\n",
    "\n",
    "# print(X_test.shape)\n",
    "\n",
    "# print(X_test[0][0][0])\n",
    "\n",
    "# print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "# print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "\n",
    "# X_train = reshape(X_train)\n",
    "# X_test = reshape(X_test)\n",
    "\n",
    "# print(X_test.shape)\n",
    "# print(X_test[0][0][0])\n",
    "\n",
    "# y_train_binary = to_categorical(Y_train, 4)\n",
    "# y_test_binary = to_categorical(Y_test, 4)\n",
    "\n",
    "# print (\"X_train shape: \" + str(X_train.shape))\n",
    "# print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "# print (\"y_train_binary shape: \" + str(y_train_binary.shape))\n",
    "# print (\"X_test shape: \" + str(X_test.shape))\n",
    "# print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "# print (\"y_test_binary shape: \" + str(y_test_binary.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Building a model in Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS660DataManagementCheck Imported\n"
     ]
    }
   ],
   "source": [
    "csDM.CS660DataManagementCheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model with  48  nodes and  1  layers.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 159, 212, 5)       130       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 79, 106, 5)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 39, 52, 10)        460       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 26, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4940)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 48)                237168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48)                192       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 196       \n",
      "=================================================================\n",
      "Total params: 238,146\n",
      "Trainable params: 238,050\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from quiver_engine import server\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 480, 640\n",
    "\n",
    "# num_classes = 4\n",
    "\n",
    "def buildModel( numOfNodes=48, numOfLayers=1):\n",
    "    \"\"\"\n",
    "    Builds the basic model.\n",
    "    Returns:\n",
    "        A Keras NN Model\n",
    "\n",
    "    \"\"\"\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 480, 640\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    num_classes = 4\n",
    "\n",
    "    print(\"Building Model with \", numOfNodes, \" nodes and \", numOfLayers, \" layers.\")\n",
    "\n",
    "    theModel = Sequential()\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(5,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=3,\n",
    "               activation='relu',\n",
    "               input_shape=input_shape\n",
    "               )\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(\n",
    "        Conv2D(\n",
    "            10,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=2,\n",
    "            activation='relu')\n",
    "    )\n",
    "    theModel.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size=(2, 2),\n",
    "            strides=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    theModel.add(Flatten())\n",
    "\n",
    "    for index in range( numOfLayers ):\n",
    "        theModel.add(Dense(numOfNodes))\n",
    "        theModel.add(BatchNormalization())\n",
    "        theModel.add(Activation('relu'))\n",
    "        theModel.add(Dropout(0.25))\n",
    "\n",
    "    theModel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    theModel.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    theModel.summary()\n",
    "    \n",
    "    return theModel\n",
    "    \n",
    "# server.launch(model)\n",
    "\n",
    "theModel = buildModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/24\n",
      "200/200 [==============================] - 3s - loss: 0.9539 - categorical_accuracy: 0.5750 - val_loss: 1.5663 - val_categorical_accuracy: 0.2500\n",
      "Epoch 2/24\n",
      "200/200 [==============================] - 3s - loss: 0.5863 - categorical_accuracy: 0.7800 - val_loss: 1.7589 - val_categorical_accuracy: 0.2750\n",
      "Epoch 3/24\n",
      "200/200 [==============================] - 3s - loss: 0.5033 - categorical_accuracy: 0.8150 - val_loss: 1.5549 - val_categorical_accuracy: 0.3750\n",
      "Epoch 4/24\n",
      "200/200 [==============================] - 3s - loss: 0.4425 - categorical_accuracy: 0.8800 - val_loss: 1.2527 - val_categorical_accuracy: 0.4750\n",
      "Epoch 5/24\n",
      "200/200 [==============================] - 3s - loss: 0.3356 - categorical_accuracy: 0.8950 - val_loss: 1.1587 - val_categorical_accuracy: 0.5000\n",
      "Epoch 6/24\n",
      "200/200 [==============================] - 5s - loss: 0.2832 - categorical_accuracy: 0.9400 - val_loss: 1.1105 - val_categorical_accuracy: 0.5500\n",
      "Epoch 7/24\n",
      "200/200 [==============================] - 3s - loss: 0.2408 - categorical_accuracy: 0.9300 - val_loss: 1.1102 - val_categorical_accuracy: 0.6500\n",
      "Epoch 8/24\n",
      "200/200 [==============================] - 4s - loss: 0.1999 - categorical_accuracy: 0.9600 - val_loss: 1.0852 - val_categorical_accuracy: 0.6250\n",
      "Epoch 9/24\n",
      "200/200 [==============================] - 3s - loss: 0.2028 - categorical_accuracy: 0.9650 - val_loss: 1.0580 - val_categorical_accuracy: 0.6750\n",
      "Epoch 10/24\n",
      "200/200 [==============================] - 3s - loss: 0.1688 - categorical_accuracy: 0.9650 - val_loss: 1.0283 - val_categorical_accuracy: 0.6500\n",
      "Epoch 11/24\n",
      "200/200 [==============================] - 3s - loss: 0.1736 - categorical_accuracy: 0.9500 - val_loss: 1.0056 - val_categorical_accuracy: 0.6750\n",
      "Epoch 12/24\n",
      "200/200 [==============================] - 3s - loss: 0.1533 - categorical_accuracy: 0.9600 - val_loss: 1.0236 - val_categorical_accuracy: 0.6000\n",
      "Epoch 13/24\n",
      "200/200 [==============================] - 3s - loss: 0.1604 - categorical_accuracy: 0.9550 - val_loss: 0.8861 - val_categorical_accuracy: 0.6750\n",
      "Epoch 14/24\n",
      "200/200 [==============================] - 3s - loss: 0.1448 - categorical_accuracy: 0.9700 - val_loss: 1.0842 - val_categorical_accuracy: 0.5500\n",
      "Epoch 15/24\n",
      "200/200 [==============================] - 2s - loss: 0.1045 - categorical_accuracy: 0.9900 - val_loss: 0.8682 - val_categorical_accuracy: 0.7250\n",
      "Epoch 16/24\n",
      "200/200 [==============================] - 3s - loss: 0.0990 - categorical_accuracy: 0.9850 - val_loss: 0.8284 - val_categorical_accuracy: 0.7000\n",
      "Epoch 17/24\n",
      "200/200 [==============================] - 3s - loss: 0.0941 - categorical_accuracy: 0.9850 - val_loss: 0.8547 - val_categorical_accuracy: 0.7250\n",
      "Epoch 18/24\n",
      "200/200 [==============================] - 3s - loss: 0.0878 - categorical_accuracy: 0.9850 - val_loss: 0.8470 - val_categorical_accuracy: 0.6750\n",
      "Epoch 19/24\n",
      "200/200 [==============================] - 3s - loss: 0.0800 - categorical_accuracy: 0.9900 - val_loss: 0.7989 - val_categorical_accuracy: 0.7250\n",
      "Epoch 20/24\n",
      "200/200 [==============================] - 3s - loss: 0.0839 - categorical_accuracy: 0.9850 - val_loss: 0.7988 - val_categorical_accuracy: 0.7250\n",
      "Epoch 21/24\n",
      "200/200 [==============================] - 2s - loss: 0.0776 - categorical_accuracy: 0.9900 - val_loss: 0.8026 - val_categorical_accuracy: 0.7500\n",
      "Epoch 22/24\n",
      "200/200 [==============================] - 2s - loss: 0.0999 - categorical_accuracy: 0.9800 - val_loss: 1.2640 - val_categorical_accuracy: 0.5500\n",
      "Epoch 23/24\n",
      "200/200 [==============================] - 3s - loss: 0.1169 - categorical_accuracy: 0.9650 - val_loss: 0.9174 - val_categorical_accuracy: 0.6250\n",
      "Epoch 24/24\n",
      "200/200 [==============================] - 3s - loss: 0.0870 - categorical_accuracy: 0.9850 - val_loss: 0.8092 - val_categorical_accuracy: 0.6750\n"
     ]
    }
   ],
   "source": [
    "# TBoardCallback = keras.callbacks.TensorBoard(\n",
    "#     log_dir='../TENSOR_LOGS/run_test', \n",
    "#     histogram_freq=0,\n",
    "#     write_graph=True,\n",
    "#     write_images=True\n",
    "# )\n",
    "\n",
    "# model.fit(x_train,\n",
    "#           y_train_as_category,\n",
    "#           batch_size=16,\n",
    "#           epochs=32,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test_as_category),\n",
    "#           callbacks = [TBoardCallback]\n",
    "#          )\n",
    "\n",
    "tensorLogDataDir = os.path.join( os.getcwd(), os.pardir, 'TENSOR_LOGS' )\n",
    "\n",
    "def trainModel( trainingName, theModel, x_train, y_train, x_test, y_test, num_classes=4 ):\n",
    "    \"\"\"\n",
    "    Trains the model via given data.\n",
    "\n",
    "    Args:\n",
    "        trainingName: A name of this train [mainly to track in TensorBoard\n",
    "        x_train: The X Set for Trainings\n",
    "        y_train: The Y set for Testing\n",
    "        x_test:  The X Set for Training/Verification\n",
    "        y_test:  The Y Set for Testing/Verification\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Reshape the X sets.\n",
    "    # Mainly for this project.because Keras/Tensor thinks in Channels.\n",
    "    # And since we are using Greyscale data, we really don't have a channel.\n",
    "    # So we have to 'fake' a channel\n",
    "    #\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "    # Convert class vectors to binary class matrices\n",
    "    y_train_as_category = to_categorical(y_train, num_classes)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    logFilePath = os.path.join( tensorLogDataDir, trainingName )\n",
    "\n",
    "    TBoardCallback = keras.callbacks.TensorBoard(\n",
    "        log_dir=logFilePath,\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=True\n",
    "    )\n",
    "\n",
    "    theModel.fit(x_train,\n",
    "              y_train_as_category,\n",
    "              batch_size=16,\n",
    "              epochs=24,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test_as_category),\n",
    "              callbacks=[TBoardCallback]\n",
    "              )\n",
    "    \n",
    "    return theModel\n",
    "\n",
    "    \n",
    "X_train, Y_train, X_test, Y_test = csDM.load_dataset( '0', 'IDEPTH' )\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "# X_test = X_test.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train_as_category = to_categorical(y_train, num_classes)\n",
    "# y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "theModel = trainModel( \"JupyterTESTRUN\", theModel, X_train, Y_train, X_test, Y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General > Test loss:  0.809247305989 Test accuracy:  0.675\n",
      "40/40 [==============================] - 0s     \n",
      "0 Results:  1  VS  [ 2.] No Match\n",
      "1 Results:  1  VS  [ 2.] No Match\n",
      "2 Results:  2  VS  [ 1.] No Match\n",
      "3 Results:  1  VS  [ 1.] Match\n",
      "4 Results:  0  VS  [ 1.] No Match\n",
      "5 Results:  3  VS  [ 2.] No Match\n",
      "6 Results:  2  VS  [ 2.] Match\n",
      "7 Results:  3  VS  [ 1.] No Match\n",
      "8 Results:  1  VS  [ 2.] No Match\n",
      "9 Results:  1  VS  [ 1.] Match\n",
      "10 Results:  0  VS  [ 0.] Match\n",
      "11 Results:  0  VS  [ 0.] Match\n",
      "12 Results:  1  VS  [ 1.] Match\n",
      "13 Results:  2  VS  [ 2.] Match\n",
      "14 Results:  1  VS  [ 2.] No Match\n",
      "15 Results:  2  VS  [ 2.] Match\n",
      "16 Results:  1  VS  [ 1.] Match\n",
      "17 Results:  1  VS  [ 1.] Match\n",
      "18 Results:  0  VS  [ 1.] No Match\n",
      "19 Results:  0  VS  [ 2.] No Match\n",
      "20 Results:  2  VS  [ 2.] Match\n",
      "21 Results:  1  VS  [ 1.] Match\n",
      "22 Results:  3  VS  [ 3.] Match\n",
      "23 Results:  3  VS  [ 3.] Match\n",
      "24 Results:  3  VS  [ 3.] Match\n",
      "25 Results:  3  VS  [ 3.] Match\n",
      "26 Results:  2  VS  [ 3.] No Match\n",
      "27 Results:  3  VS  [ 3.] Match\n",
      "28 Results:  1  VS  [ 3.] No Match\n",
      "29 Results:  3  VS  [ 3.] Match\n",
      "30 Results:  3  VS  [ 3.] Match\n",
      "31 Results:  1  VS  [ 3.] No Match\n",
      "32 Results:  0  VS  [ 0.] Match\n",
      "33 Results:  0  VS  [ 0.] Match\n",
      "34 Results:  0  VS  [ 0.] Match\n",
      "35 Results:  0  VS  [ 0.] Match\n",
      "36 Results:  0  VS  [ 0.] Match\n",
      "37 Results:  0  VS  [ 0.] Match\n",
      "38 Results:  0  VS  [ 0.] Match\n",
      "39 Results:  0  VS  [ 0.] Match\n",
      "[10, 6, 4, 7]\n",
      "[1.0, 0.6, 0.4, 0.7]\n"
     ]
    }
   ],
   "source": [
    "# score = model.evaluate(x_test, y_test_as_category, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"../MODELS/modelTEST.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"../WEIGHTS/modelTEST.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "\n",
    "def evaluateModel( theModel, x_test, y_test, num_classes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "    score = theModel.evaluate(x_test, y_test_as_category, verbose=0)\n",
    "    print('General > Test loss: ', score[0], 'Test accuracy: ', score[1] )\n",
    "\n",
    "    predictionResults = theModel.predict_classes(x_test, verbose=1)\n",
    "    \n",
    "    scoringList = [0, 0, 0, 0]\n",
    "    scoringListAsPecents = []\n",
    "    \n",
    "    for index in range(len(x_test)):\n",
    "        if( predictionResults[index] == y_test[index] ):\n",
    "            print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"Match\" )\n",
    "            scoringList[ int(y_test[index]) ] = scoringList[ int(y_test[index]) ] + 1\n",
    "        else:\n",
    "            print( index, 'Results: ', predictionResults[index], \" VS \", y_test[index], \"No Match\" )\n",
    "    \n",
    "    for element in scoringList:\n",
    "        scoringListAsPecents.append( element / 10.0 )\n",
    "    \n",
    "    print(scoringList )\n",
    "        \n",
    "    return { 'SCORE': score, 'SCORELIST' : scoringListAsPecents }\n",
    "\n",
    "\n",
    "X_train_Z, Y_train_Z, X_test_Z, Y_test_Z = csDM.load_dataset( '0', 'IDEPTH' )\n",
    "\n",
    "scoringResults = evaluateModel( theModel, X_test_Z, Y_test_Z, 4)\n",
    "print(scoringResults['SCORELIST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Everything Saved\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "modelsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS' )\n",
    "modelsStructsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS_STRUCTS' )\n",
    "weightsDirectory = os.path.join( os.getcwd(), os.pardir, 'WEIGHTS' )\n",
    "\n",
    "def saveModelEverything( theModel, modelName ):\n",
    "    saveModelStructure( theModel, modelName )\n",
    "    saveModel( theModel, modelName )\n",
    "    saveModelJSON( theModel, modelName )\n",
    "    saveModelWeights( theModel, modelName )\n",
    "    \n",
    "    print(\"Model Everything Saved\")\n",
    "    \n",
    "\n",
    "def saveModelStructure( theModel, modelStructureName ):\n",
    "    modelStructsFilePath = os.path.join(modelsStructsDirectory, modelStructureName )\n",
    "    plot_model(theModel, to_file=modelStructsFilePath)\n",
    "\n",
    "\n",
    "def saveModelJSON( model, modelName ):\n",
    "    \"\"\"\n",
    "    Saves the Model as JSON\n",
    "    Args:\n",
    "        model: the Keras NN Model\n",
    "        modelName: the Name\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    modelFilePath = os.path.join( modelsDirectory, modelName + '.json' )\n",
    "    model_json = theModel.to_json()\n",
    "    with open( modelFilePath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "        \n",
    "def saveModel( model, modelName ):\n",
    "    theModel.save(os.path.join( modelsDirectory, modelName ))\n",
    "\n",
    "    \n",
    "def saveModelWeights( theModel, modelName ):\n",
    "    \"\"\"\n",
    "    Saved the Model Weights\n",
    "    Args:\n",
    "        weights: The Weights\n",
    "        weightName: Weight Names\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    weightsFilePath = os.path.join( weightsDirectory, modelName + '.h5' )\n",
    "    theModel.save_weights( weightsFilePath )\n",
    "    \n",
    "    \n",
    "saveModelEverything( theModel, 'JUPYTER_MODEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL Loaded.\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "modelsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS' )\n",
    "modelsStructsDirectory = os.path.join( os.getcwd(), os.pardir, 'MODELS_STRUCTS' )\n",
    "weightsDirectory = os.path.join( os.getcwd(), os.pardir, 'WEIGHTS' )\n",
    "\n",
    "\n",
    "def loadModel( modelName ):\n",
    "    theModel = load_model( os.path.join( modelsDirectory, modelName) )\n",
    "    print('MODEL Loaded.')\n",
    "    return theModel\n",
    "\n",
    "\n",
    "theModel = loadModel( 'JUPYTER_MODEL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"NA\" = 0\n",
    "\n",
    "\"UP\" = 1\n",
    "\n",
    "\"DOWN\" = 2\n",
    "\n",
    "\"HOLE\" = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15082659341, 15082659780, 15082659991, 15082660511, 15082660960, 15082660961, 15082661161, 15082661501, 15082662161, 15082662270, 15082663891, 15082664091, 15082664601, 15082665020, 15082665311, 15082666170, 15082667151, 15082667570, 15082667810, 15082668930, 15082669461, 15082669791, 15082669871, 15082670830, 15082671231, 15082671520, 15082675760, 15082676751, 15084364111, 15084364160, 15084364331, 15084365171, 15084365451, 15084365961, 15084366231, 15084367311, 15084367441, 15084368130, 15084368181, 15084372260, 15084372410, 15084375351, 15084375991, 15084376560, 15084377390, 15084377690, 15085973190, 15085973270, 15085973660, 15085974300, 15085974520, 15085974741, 15085975061, 15085984200, 15085984831, 15085985191, 15085985260, 15085985261, 15085985440, 15085985501, 15085985580, 15085985660, 15085986071, 15085986151, 15085986530, 15085987091, 15085987241, 15085987681, 15085987740, 15085987930, 15085988600, 15085989391, 15085989540, 15085990070, 15085990910, 15085990970, 15085993800, 15085993931, 15085994070, 15085994131, 15085994350, 15085995071, 15085995341, 15085997600, 15085997601, 15085997781, 15085998160, 15085998540, 15085998541, 15085998611, 15085998730, 15085998801, 15085998921, 15087876140, 15087876210, 15087877330, 15087877480, 15087879350, 15087879740, 15087880490, 15087880811, 15087881820, 15087882080, 15087882081, 15087882500, 15087883211, 15087884820, 15087885540, 15087886240, 15087886310, 15087886811, 15087887090, 15087887430, 15087887760, 15087888240, 15087888501, 15089592930, 15089593011, 15089593381, 15089593981, 15089594821, 15089595081, 15089595210, 15089595521, 15089595620, 15089595870, 15089596081, 15089596170, 15089596671, 15089596741, 15089596830, 15089596911, 15089597780, 15089599441, 15089599750, 15089599930, 15089600200, 15089601321, 15089601900, 15089602190, 15089602331, 15089602431, 15089602590, 15089603780, 15089603850, 15089604241, 15089604291, 15089604440, 15089604631, 15089604780, 15089604781, 15089605781, 15089606061, 15089606291, 15089606391, 15089606451, 15089606591, 15089606641, 15089607390, 15091319151, 15091322530, 15091322671, 15091323431, 15091324130, 15091324240, 15091324361, 15093895130, 15093896991, 15093897280, 15093898721, 15093902261, 15093904421, 15093904590, 15093905350, 15093906530, 15093907141, 15093907201, 15093907540, 15093909071, 15093910350, 15093910990, 15093911430, 15093912140, 15093912800, 15093914480, 15093915980, 15093919221, 15093919511, 15093919931, 15093920101, 15106028620, 15106031850, 15106032690, 15106033120, 15106033991, 15106034910, 15106036581, 15106036780, 15106036901, 15106037481] \n",
      " [15082660330, 15082661750, 15082665650, 15082670181, 15082676701, 15084364851, 15084365230, 15084367501, 15084375680, 15084377920, 15085973530, 15085974811, 15085983641, 15085985730, 15085985781, 15085987090, 15085987861, 15087876411, 15087877561, 15087878160, 15087880941, 15087885260, 15089593921, 15089594890, 15089595801, 15089595941, 15089599700, 15089603681, 15089607800, 15091322481, 15091323161, 15091323630, 15093896680, 15093898990, 15093902260, 15093912030, 15093912461, 15093912631, 15093919270, 15106028410]\n"
     ]
    }
   ],
   "source": [
    "X_train_Z, Y_train_Z, TrainingList, X_test_Z, Y_test_Z, TestList = csDM.load_datasetAndGetBaseLists( '0', 'IDEPTH' )\n",
    "print(TrainingList, \"\\n\", TestList )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15082659870, 15082664350, 15082664830, 15082667491, 15082676750, 15084363910, 15084364560, 15084365120, 15084367640, 15084372330, 15085973920, 15085973921, 15085974371, 15085983780, 15085987620, 15085991100, 15085991440, 15085994501, 15085995340, 15085995510, 15085997850, 15085998041, 15087879810, 15087880861, 15087888241, 15089593681, 15089599231, 15089599501, 15089600161, 15089601261, 15089602130, 15089602381, 15089604071, 15089605090, 15091324300, 15093901541, 15093904710, 15093907491, 15106028950, 15106033660]\n"
     ]
    }
   ],
   "source": [
    "print(csDM.getTestList(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
