{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-660 Semester Project Notebook 1\n",
    "\n",
    "## Stan Rosenbaum\n",
    "\n",
    "Fall 2017\n",
    "\n",
    "Anaconda 5 / Python 3\n",
    "\n",
    "Using Keras with TensorFlow as back end.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we init stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS660DataManagementCheck Imported\n"
     ]
    }
   ],
   "source": [
    "# Load the Basic Python Libraries\n",
    "import os\n",
    "import csv\n",
    "import PIL\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Load my Data Management Module\n",
    "import CS660DataManagement as csDM\n",
    "\n",
    "# load numpy\n",
    "import numpy as np\n",
    "\n",
    "# Load Keras Studd\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Other\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "# Not sure what this is:\n",
    "# from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get Processed Data Directory.\n",
    "processedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PROCESSED' )\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "pickleDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'PICKLES' )\n",
    "\n",
    "testImageColorFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'ICOLOR', 'TEST.png' )\n",
    "testImageDepthFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'IDEPTH', 'TEST.png' )\n",
    "testCSVFile = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED', 'PCLOUD', 'TEST.csv' )\n",
    "\n",
    "combinedDataDir = os.path.join( os.getcwd(), os.pardir, 'DATA', 'COMBINED' )\n",
    "\n",
    "imageDirs = ['ICOLOR', 'IDEPTH']\n",
    "csvDirs = ['PCLOUD']\n",
    "\n",
    "allDataFlavors = imageDirs + csvDirs\n",
    "\n",
    "#Load main data file.\n",
    "searCSVInfoFile = os.path.join( combinedDataDir, 'SEAR_DC_INFO.csv' )\n",
    "\n",
    "CS660DataManagement.CS660DataManagementCheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities for Retreiveing the CSVInfoData from Files"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 11,
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901\n",
      "Number of Everything\n",
      "UPs: 278\n",
      "DOWNs: 201\n",
      "NAs: 204\n",
      "HOLEs: 218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "print( len( csDM.getListOfDataCSVFileKeys() ) )\n",
    "csDM.reportStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliies for Creating the Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 22,
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "def reshape(trainingSet):\n",
    "    \"\"\"\n",
    "    This is to add the 'Channels' Dimension for Keras.\n",
    "    \"\"\"\n",
    "    getShape = trainingSet.shape\n",
    "    newShape = getShape + (1,)\n",
    "    return trainingSet.reshape(newShape)\n",
    "    \n",
    "\n",
    "X_train, Y_train, X_test, Y_test = csDM.load_dataset( '1', 'ICOLOR' )\n",
    "\n",
    "\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "\n",
    "X_train = reshape(X_train)\n",
    "X_test = reshape(X_test)\n",
    "\n",
    "y_train_binary = to_categorical(Y_train, 4)\n",
    "y_test_binary = to_categorical(Y_test, 4)\n",
    "\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"y_train_binary shape: \" + str(y_train_binary.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"y_test_binary shape: \" + str(y_test_binary.shape))\n",
=======
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils for converting Training and Test Sets into Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640)\n",
      "255\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 7,
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "x_train shape: (100, 480, 640, 1)\n",
      "100 train samples\n",
      "20 test samples\n",
      "x_train shape: (100, 480, 640, 1)\n",
      "(100, 4) y_train shape\n",
      "(20, 4) y_test shape\n",
      "Train on 100 samples, validate on 20 samples\n",
      "Epoch 1/25\n",
      "100/100 [==============================] - 16s - loss: 1.5992 - categorical_accuracy: 0.2800 - val_loss: 1.3208 - val_categorical_accuracy: 0.3000\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - 15s - loss: 1.2898 - categorical_accuracy: 0.3200 - val_loss: 1.1484 - val_categorical_accuracy: 0.5500\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - 15s - loss: 0.9671 - categorical_accuracy: 0.7300 - val_loss: 0.9777 - val_categorical_accuracy: 0.7500\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - 15s - loss: 0.4137 - categorical_accuracy: 0.9100 - val_loss: 0.9408 - val_categorical_accuracy: 0.5500\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - 15s - loss: 0.1211 - categorical_accuracy: 0.9700 - val_loss: 1.6178 - val_categorical_accuracy: 0.6000\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - 15s - loss: 0.0524 - categorical_accuracy: 0.9800 - val_loss: 1.6165 - val_categorical_accuracy: 0.5500\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - 15s - loss: 0.0299 - categorical_accuracy: 0.9900 - val_loss: 3.9281 - val_categorical_accuracy: 0.4500\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - 15s - loss: 0.2217 - categorical_accuracy: 0.9100 - val_loss: 2.2946 - val_categorical_accuracy: 0.5500\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - 15s - loss: 0.0401 - categorical_accuracy: 0.9900 - val_loss: 2.0216 - val_categorical_accuracy: 0.6500\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - 15s - loss: 0.0500 - categorical_accuracy: 0.9800 - val_loss: 1.2396 - val_categorical_accuracy: 0.7500\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - 15s - loss: 0.0751 - categorical_accuracy: 0.9800 - val_loss: 2.9251 - val_categorical_accuracy: 0.5500\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - 15s - loss: 0.1401 - categorical_accuracy: 0.9700 - val_loss: 2.2682 - val_categorical_accuracy: 0.6000\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - 16s - loss: 0.0199 - categorical_accuracy: 1.0000 - val_loss: 1.5402 - val_categorical_accuracy: 0.6500\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - 16s - loss: 0.0088 - categorical_accuracy: 1.0000 - val_loss: 1.3356 - val_categorical_accuracy: 0.6500\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - 15s - loss: 0.0035 - categorical_accuracy: 1.0000 - val_loss: 1.2834 - val_categorical_accuracy: 0.6500\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - 15s - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 1.3534 - val_categorical_accuracy: 0.6500\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - 15s - loss: 5.5869e-04 - categorical_accuracy: 1.0000 - val_loss: 1.4745 - val_categorical_accuracy: 0.6500\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - 15s - loss: 2.0909e-04 - categorical_accuracy: 1.0000 - val_loss: 1.5740 - val_categorical_accuracy: 0.7000\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - 15s - loss: 1.2432e-04 - categorical_accuracy: 1.0000 - val_loss: 1.6558 - val_categorical_accuracy: 0.7000\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - 15s - loss: 7.3554e-05 - categorical_accuracy: 1.0000 - val_loss: 1.7109 - val_categorical_accuracy: 0.7000\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - 15s - loss: 5.2865e-05 - categorical_accuracy: 1.0000 - val_loss: 1.7510 - val_categorical_accuracy: 0.7000\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - 15s - loss: 3.8805e-05 - categorical_accuracy: 1.0000 - val_loss: 1.7755 - val_categorical_accuracy: 0.7000\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - 15s - loss: 3.2513e-05 - categorical_accuracy: 1.0000 - val_loss: 1.7862 - val_categorical_accuracy: 0.7000\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - 15s - loss: 2.5415e-05 - categorical_accuracy: 1.0000 - val_loss: 1.8119 - val_categorical_accuracy: 0.6500\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - 15s - loss: 2.0475e-05 - categorical_accuracy: 1.0000 - val_loss: 1.8381 - val_categorical_accuracy: 0.6500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_8 to have shape (None, 4) but got array with shape (20, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5b35f3e9a076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m          )\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m    894\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1383\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1384\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/anaconda/envs/CS_660_Semester_Project/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_8 to have shape (None, 4) but got array with shape (20, 1)"
=======
      "901\n",
      "Number of Everything\n",
      "UPs: 278\n",
      "DOWNs: 201\n",
      "NAs: 204\n",
      "HOLEs: 218\n",
      "10\n",
      "(480, 640)\n",
      "255\n",
      "5\n"
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import keras\n",
    "from quiver_engine import server\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 480, 640\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "x_train, y_train, x_test, y_test = csDM.load_dataset( '1', 'ICOLOR' )\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train_as_category = to_categorical(y_train, num_classes)\n",
    "y_test_as_category = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(y_train_as_category.shape, 'y_train shape')\n",
    "print(y_test_as_category.shape, 'y_test shape')\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(5, \n",
    "           kernel_size=(5, 5),\n",
    "           activation='relu',\n",
    "           input_shape=input_shape\n",
    "          )\n",
    ")\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        10, \n",
    "        kernel_size=(2, 2), \n",
    "        activation='relu')\n",
    ")\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
=======
    "# Checking Utility Functions.\n",
    "print( len( csDM.getListOfDataCSVFileKeys() ) )\n",
    "csDM.reportStats()\n",
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
    "\n",
    "\n",
<<<<<<< HEAD
    "TBoardCallback = keras.callbacks.TensorBoard(\n",
    "    log_dir='../TENSOR_LOGS/run_test', \n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True\n",
    ")\n",
    "\n",
    "model.fit(x_train,\n",
    "          y_train_as_category,\n",
    "          batch_size=16,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test_as_category),\n",
    "          callbacks = [TBoardCallback]\n",
    "         )\n",
    "\n"
=======
    "allLists = csDM.unpickleAllTrainAndTestLists()\n",
    "\n",
    "print( str(len(allLists['TrainingLists'])))\n",
    "\n",
    "testImageArray = csDM.getImageFileAsNPArray(testImageColorFile)\n",
    "    \n",
    "print(testImageArray.shape)\n",
    "print(np.max(testImageArray))\n",
    "print(np.min(testImageArray))\n"
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 16,
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Test loss: 1.83807682991\n",
      "Test accuracy: 0.649999976158\n",
      "Saved model to disk\n"
=======
      "CS660DataManagementCheck Imported\n"
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "score = model.evaluate(x_test, y_test_as_category, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"../MODELS/modelTEST.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../WEIGHTS/modelTEST.h5\")\n",
    "print(\"Saved model to disk\")"
=======
    "CS660DataManagement.CS660DataManagementCheck()"
>>>>>>> parent of a7f1deb... Working NN Code in Keras.
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 480, 640, 1)\n",
      "20/20 [==============================] - 0s\n",
      "[2 2 1 3 2 2 2 1 3 1 2 3 3 3 3 3 1 1 0 0]\n",
      "prediction of [1]:  2   [ 2.]\n",
      "prediction of [1]:  2   [ 2.]\n",
      "prediction of [1]:  1   [ 1.]\n",
      "prediction of [1]:  3   [ 2.]\n",
      "prediction of [1]:  2   [ 1.]\n",
      "prediction of [1]:  2   [ 1.]\n",
      "prediction of [1]:  2   [ 2.]\n",
      "prediction of [1]:  1   [ 0.]\n",
      "prediction of [1]:  3   [ 1.]\n",
      "prediction of [1]:  1   [ 1.]\n",
      "prediction of [1]:  2   [ 2.]\n",
      "prediction of [1]:  3   [ 3.]\n",
      "prediction of [1]:  3   [ 3.]\n",
      "prediction of [1]:  3   [ 3.]\n",
      "prediction of [1]:  3   [ 3.]\n",
      "prediction of [1]:  3   [ 3.]\n",
      "prediction of [1]:  1   [ 0.]\n",
      "prediction of [1]:  1   [ 0.]\n",
      "prediction of [1]:  0   [ 0.]\n",
      "prediction of [1]:  0   [ 0.]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print(x_test.shape)\n",
    "asdf = model.predict_classes(x_test, verbose=1)\n",
    "print(asdf)\n",
    "for index in range(len(x_test)):\n",
    "    print('prediction of [1]: ', asdf[index], \" \", y_test[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/staque/Development/GitHub/CS-660-Semester-Project/ANACONDA'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
